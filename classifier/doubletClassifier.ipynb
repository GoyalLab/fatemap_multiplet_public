{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training a doublet classifier on DNA barcoded \"ground truth\" singlets for Zhang Melzer et al. 2023\n",
    "### Created by Madeline E Melzer on 20231110\n",
    "### Last edited by Madeline E Melzer on 20240516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xgboost\n",
    "import sklearn\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy\n",
    "from scipy.io import mmread\n",
    "import anndata\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from joblib import dump, load\n",
    "print(xgboost.__version__)\n",
    "\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### variable doublet rates\n",
    "\n",
    "dataset_list = [\"0.05\", \"0.08\", \"0.10\", \"0.15\", \"0.20\", \"0.25\"]\n",
    "results_dir = \"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier/results/\"\n",
    "classifiers_dir = \"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier/classifiers/\"\n",
    "\n",
    "#summary = pd.DataFrame(columns = [\"dataset\", \"condition\", \"auroc\", \"auprc\", \"accuracy\", \"best_params\"])\n",
    "\n",
    "for dataset in dataset_list:\n",
    "    for count in range(10):\n",
    "        dataset_summary_df = main(dataset)\n",
    "        summary = pd.concat([summary, dataset_summary_df])\n",
    "    summary.to_csv(f\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier/results/datasetSummaries/{dataset}.csv\", index = False)\n",
    "\n",
    "summary.to_csv(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier/results/summary_variableDoubletRates.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 285, 'singlet': 2591}\n",
      "100%|██████████| 10/10 [00:33<00:00,  3.31s/trial, best loss: -0.8182284681078825]\n",
      "sample1 Best parameters for tree: {'colsample_bytree': 0.6791383453771085, 'gamma': 0.2640188975266044, 'learning_rate': 0.2764557012206551, 'max_depth': 4, 'min_child_weight': 5, 'n_estimators': 80, 'reg_alpha': 0.47664367717913625, 'reg_lambda': 2.074156653860055, 'scale_pos_weight': 61.61526825026569, 'subsample': 0.8911530928797715}\n",
      "sample1 Best tree score: {'loss': -0.8182284681078825, 'accuracy': 0.9513888888888888, 'status': 'ok', 'auroc': 0.950782544028665, 'auprc': 0.8182284681078825}\n",
      "sample1 AUROC: 0.9662331504436767\n",
      "sample1 AUPRC: 0.8712190274752258\n",
      "sample1 Accuracy: 0.9669565217391304\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample1   sample1  0.966233  0.871219  0.966957   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 81, 'max_depth': 5, 'learning...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:37<00:00,  3.78s/trial, best loss: -0.1353671055298151]\n",
      "sample1_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.8827708529882821, 'gamma': 0.7692207916253541, 'learning_rate': 0.3662598181760541, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 87, 'reg_alpha': 0.21092288617152333, 'reg_lambda': 2.8355245401750797, 'scale_pos_weight': 3.9311173546777045, 'subsample': 0.6679245342241802}\n",
      "sample1_neg_control_scrambled Best tree score: {'loss': -0.1353671055298151, 'accuracy': 0.8975694444444444, 'status': 'ok', 'auroc': 0.6334719264442417, 'auprc': 0.1353671055298151}\n",
      "sample1_neg_control_scrambled AUROC: 0.45888369572580096\n",
      "sample1_neg_control_scrambled AUPRC: 0.09643445223353081\n",
      "sample1_neg_control_scrambled Accuracy: 0.9008695652173913\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample1                        sample1  0.966233  0.871219  0.966957   \n",
      "1  sample1  sample1_neg_control_scrambled  0.458884  0.096434  0.900870   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 81, 'max_depth': 5, 'learning...  \n",
      "1  {'n_estimators': 88, 'max_depth': 7, 'learning...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/488009245.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary = pd.concat([summary, dataset_summary_df])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 285, 'singlet': 2591}\n",
      "100%|██████████| 10/10 [00:27<00:00,  2.70s/trial, best loss: -0.8469214607346068]\n",
      "sample1 Best parameters for tree: {'colsample_bytree': 0.7609286216609517, 'gamma': 0.13545222290254058, 'learning_rate': 0.4802009299962159, 'max_depth': 17, 'min_child_weight': 2, 'n_estimators': 42, 'reg_alpha': 0.7497926624163822, 'reg_lambda': 1.9621895371240643, 'scale_pos_weight': 30.71593993080512, 'subsample': 0.7910143139619341}\n",
      "sample1 Best tree score: {'loss': -0.8469214607346068, 'accuracy': 0.9496527777777778, 'status': 'ok', 'auroc': 0.965486935064057, 'auprc': 0.8469214607346068}\n",
      "sample1 AUROC: 0.934633882002303\n",
      "sample1 AUPRC: 0.7628154979197006\n",
      "sample1 Accuracy: 0.9443478260869566\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample1   sample1  0.934634  0.762815  0.944348   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 43, 'max_depth': 18, 'learnin...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:39<00:00,  3.95s/trial, best loss: -0.1231581692401844]\n",
      "sample1_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.7158280005517805, 'gamma': 0.8008779101458102, 'learning_rate': 0.6124462765306283, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 97, 'reg_alpha': 0.8356106952169191, 'reg_lambda': 1.683062212234173, 'scale_pos_weight': 92.76097045290388, 'subsample': 0.8241033710544237}\n",
      "sample1_neg_control_scrambled Best tree score: {'loss': -0.1231581692401844, 'accuracy': 0.8333333333333334, 'status': 'ok', 'auroc': 0.5644119933745732, 'auprc': 0.1231581692401844}\n",
      "sample1_neg_control_scrambled AUROC: 0.5934769355821987\n",
      "sample1_neg_control_scrambled AUPRC: 0.12747717990995638\n",
      "sample1_neg_control_scrambled Accuracy: 0.8330434782608696\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample1                        sample1  0.934634  0.762815  0.944348   \n",
      "1  sample1  sample1_neg_control_scrambled  0.593477  0.127477  0.833043   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 43, 'max_depth': 18, 'learnin...  \n",
      "1  {'n_estimators': 98, 'max_depth': 8, 'learning...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 285, 'singlet': 2591}\n",
      "100%|██████████| 10/10 [00:29<00:00,  2.90s/trial, best loss: -0.8618289049387888]\n",
      "sample1 Best parameters for tree: {'colsample_bytree': 0.556933733061765, 'gamma': 0.18833242125132718, 'learning_rate': 0.13924323989249354, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 88, 'reg_alpha': 0.5487302326338065, 'reg_lambda': 1.7454071281812162, 'scale_pos_weight': 51.15027136429854, 'subsample': 0.9303178582279117}\n",
      "sample1 Best tree score: {'loss': -0.8618289049387888, 'accuracy': 0.9618055555555556, 'status': 'ok', 'auroc': 0.9625798600547613, 'auprc': 0.8618289049387888}\n",
      "sample1 AUROC: 0.9823884034410351\n",
      "sample1 AUPRC: 0.8849850419841915\n",
      "sample1 Accuracy: 0.9565217391304348\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample1   sample1  0.982388  0.884985  0.956522   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 89, 'max_depth': 5, 'learning...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:41<00:00,  4.17s/trial, best loss: -0.12611982365465058]\n",
      "sample1_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.9809165635336575, 'gamma': 0.2893330469759434, 'learning_rate': 0.9854453924872291, 'max_depth': 8, 'min_child_weight': 6, 'n_estimators': 50, 'reg_alpha': 0.9168022896259536, 'reg_lambda': 1.593461704824197, 'scale_pos_weight': 77.90798506872724, 'subsample': 0.7899829342615585}\n",
      "sample1_neg_control_scrambled Best tree score: {'loss': -0.12611982365465058, 'accuracy': 0.8090277777777778, 'status': 'ok', 'auroc': 0.5682317547239969, 'auprc': 0.12611982365465058}\n",
      "sample1_neg_control_scrambled AUROC: 0.49187157081893923\n",
      "sample1_neg_control_scrambled AUPRC: 0.09860811255307289\n",
      "sample1_neg_control_scrambled Accuracy: 0.8260869565217391\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample1                        sample1  0.982388  0.884985  0.956522   \n",
      "1  sample1  sample1_neg_control_scrambled  0.491872  0.098608  0.826087   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 89, 'max_depth': 5, 'learning...  \n",
      "1  {'n_estimators': 51, 'max_depth': 9, 'learning...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 285, 'singlet': 2591}\n",
      "100%|██████████| 10/10 [00:20<00:00,  2.03s/trial, best loss: -0.8854501493898012]\n",
      "sample1 Best parameters for tree: {'colsample_bytree': 0.6376133919147629, 'gamma': 0.8443571144388237, 'learning_rate': 0.7574601668563951, 'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 66, 'reg_alpha': 0.03356652882774147, 'reg_lambda': 2.3563595452637376, 'scale_pos_weight': 57.669270294193474, 'subsample': 0.9181573122398373}\n",
      "sample1 Best tree score: {'loss': -0.8854501493898012, 'accuracy': 0.9496527777777778, 'status': 'ok', 'auroc': 0.972044755433864, 'auprc': 0.8854501493898012}\n",
      "sample1 AUROC: 0.8999187157081893\n",
      "sample1 AUPRC: 0.6600948194523726\n",
      "sample1 Accuracy: 0.9339130434782609\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample1   sample1  0.899919  0.660095  0.933913   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 67, 'max_depth': 2, 'learning...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:31<00:00,  3.14s/trial, best loss: -0.12668609528509692]\n",
      "sample1_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.744675626254282, 'gamma': 0.600203304975212, 'learning_rate': 0.6807694368956706, 'max_depth': 15, 'min_child_weight': 1, 'n_estimators': 51, 'reg_alpha': 0.7883415902219757, 'reg_lambda': 2.3605584166406235, 'scale_pos_weight': 31.671698670566553, 'subsample': 0.8193678745220001}\n",
      "sample1_neg_control_scrambled Best tree score: {'loss': -0.12668609528509692, 'accuracy': 0.8715277777777778, 'status': 'ok', 'auroc': 0.5852347632085995, 'auprc': 0.12668609528509692}\n",
      "sample1_neg_control_scrambled AUROC: 0.5196437038542301\n",
      "sample1_neg_control_scrambled AUPRC: 0.10740978338717923\n",
      "sample1_neg_control_scrambled Accuracy: 0.8695652173913043\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample1                        sample1  0.899919  0.660095  0.933913   \n",
      "1  sample1  sample1_neg_control_scrambled  0.519644  0.107410  0.869565   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 67, 'max_depth': 2, 'learning...  \n",
      "1  {'n_estimators': 52, 'max_depth': 16, 'learnin...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 285, 'singlet': 2591}\n",
      "100%|██████████| 10/10 [00:25<00:00,  2.59s/trial, best loss: -0.8721723773453001]\n",
      "sample1 Best parameters for tree: {'colsample_bytree': 0.9586721383936105, 'gamma': 0.6779215695239788, 'learning_rate': 0.08761164146014432, 'max_depth': 5, 'min_child_weight': 0, 'n_estimators': 63, 'reg_alpha': 0.31047121221141394, 'reg_lambda': 1.632174184563445, 'scale_pos_weight': 96.6626969245438, 'subsample': 0.8377458938087646}\n",
      "sample1 Best tree score: {'loss': -0.8721723773453001, 'accuracy': 0.9565972222222222, 'status': 'ok', 'auroc': 0.9763039583544603, 'auprc': 0.8721723773453001}\n",
      "sample1 AUROC: 0.9580369843527738\n",
      "sample1 AUPRC: 0.7970579826426498\n",
      "sample1 Accuracy: 0.9373913043478261\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample1   sample1  0.958037  0.797058  0.937391   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 64, 'max_depth': 6, 'learning...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:33<00:00,  3.33s/trial, best loss: -0.12949846298614512]\n",
      "sample1_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.8701024425301858, 'gamma': 0.9456604522038148, 'learning_rate': 0.7925533788700677, 'max_depth': 16, 'min_child_weight': 6, 'n_estimators': 74, 'reg_alpha': 0.44736260614619117, 'reg_lambda': 1.852947162436884, 'scale_pos_weight': 35.349472801706575, 'subsample': 0.7924696621683596}\n",
      "sample1_neg_control_scrambled Best tree score: {'loss': -0.12949846298614512, 'accuracy': 0.8263888888888888, 'status': 'ok', 'auroc': 0.5295270932630227, 'auprc': 0.12949846298614512}\n",
      "sample1_neg_control_scrambled AUROC: 0.5053512158775316\n",
      "sample1_neg_control_scrambled AUPRC: 0.10676817231806868\n",
      "sample1_neg_control_scrambled Accuracy: 0.8226086956521739\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample1                        sample1  0.958037  0.797058  0.937391   \n",
      "1  sample1  sample1_neg_control_scrambled  0.505351  0.106768  0.822609   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 64, 'max_depth': 6, 'learning...  \n",
      "1  {'n_estimators': 75, 'max_depth': 17, 'learnin...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 285, 'singlet': 2591}\n",
      "100%|██████████| 10/10 [00:38<00:00,  3.87s/trial, best loss: -0.8850149239563009]\n",
      "sample1 Best parameters for tree: {'colsample_bytree': 0.5325821281604277, 'gamma': 0.11538910942203034, 'learning_rate': 0.2964444573540529, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 75, 'reg_alpha': 0.9529264737604596, 'reg_lambda': 1.6102687815969685, 'scale_pos_weight': 13.986580836009914, 'subsample': 0.6538495438083458}\n",
      "sample1 Best tree score: {'loss': -0.8850149239563009, 'accuracy': 0.9618055555555556, 'status': 'ok', 'auroc': 0.9720785586316465, 'auprc': 0.8850149239563009}\n",
      "sample1 AUROC: 0.9473345525977105\n",
      "sample1 AUPRC: 0.8183060154000239\n",
      "sample1 Accuracy: 0.9478260869565217\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample1   sample1  0.947335  0.818306  0.947826   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 76, 'max_depth': 10, 'learnin...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:26<00:00,  2.68s/trial, best loss: -0.12824189978969455]\n",
      "sample1_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.6202598348165553, 'gamma': 0.5575329187701609, 'learning_rate': 0.22592500619236602, 'max_depth': 8, 'min_child_weight': 7, 'n_estimators': 56, 'reg_alpha': 0.6169537996572592, 'reg_lambda': 2.9163029495369672, 'scale_pos_weight': 6.38085083610561, 'subsample': 0.5942226574836273}\n",
      "sample1_neg_control_scrambled Best tree score: {'loss': -0.12824189978969455, 'accuracy': 0.8993055555555556, 'status': 'ok', 'auroc': 0.5460906601764527, 'auprc': 0.12824189978969455}\n",
      "sample1_neg_control_scrambled AUROC: 0.535257061572851\n",
      "sample1_neg_control_scrambled AUPRC: 0.10780351753921841\n",
      "sample1_neg_control_scrambled Accuracy: 0.8921739130434783\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample1                        sample1  0.947335  0.818306  0.947826   \n",
      "1  sample1  sample1_neg_control_scrambled  0.535257  0.107804  0.892174   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 76, 'max_depth': 10, 'learnin...  \n",
      "1  {'n_estimators': 57, 'max_depth': 9, 'learning...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 285, 'singlet': 2591}\n",
      "100%|██████████| 10/10 [00:25<00:00,  2.55s/trial, best loss: -0.8644488869217994]\n",
      "sample1 Best parameters for tree: {'colsample_bytree': 0.5514686030972336, 'gamma': 0.16553490652288225, 'learning_rate': 0.14210487606808386, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 87, 'reg_alpha': 0.9916008090943519, 'reg_lambda': 2.272019375412381, 'scale_pos_weight': 77.71975220829401, 'subsample': 0.7551516990378093}\n",
      "sample1 Best tree score: {'loss': -0.8644488869217994, 'accuracy': 0.9635416666666666, 'status': 'ok', 'auroc': 0.9544332893891762, 'auprc': 0.8644488869217994}\n",
      "sample1 AUROC: 0.9821851927115085\n",
      "sample1 AUPRC: 0.9242086445242886\n",
      "sample1 Accuracy: 0.9739130434782609\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample1   sample1  0.982185  0.924209  0.973913   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 88, 'max_depth': 7, 'learning...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:37<00:00,  3.74s/trial, best loss: -0.15308393917420932]\n",
      "sample1_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.5859977717371869, 'gamma': 0.9070759950603227, 'learning_rate': 0.6897088461594026, 'max_depth': 18, 'min_child_weight': 5, 'n_estimators': 51, 'reg_alpha': 0.7863958538705595, 'reg_lambda': 1.442781468157694, 'scale_pos_weight': 53.54930372728957, 'subsample': 0.5746617024920584}\n",
      "sample1_neg_control_scrambled Best tree score: {'loss': -0.15308393917420932, 'accuracy': 0.8454861111111112, 'status': 'ok', 'auroc': 0.5686711962951695, 'auprc': 0.15308393917420932}\n",
      "sample1_neg_control_scrambled AUROC: 0.4945471787577051\n",
      "sample1_neg_control_scrambled AUPRC: 0.10309885649653966\n",
      "sample1_neg_control_scrambled Accuracy: 0.8208695652173913\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample1                        sample1  0.982185  0.924209  0.973913   \n",
      "1  sample1  sample1_neg_control_scrambled  0.494547  0.103099  0.820870   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 88, 'max_depth': 7, 'learning...  \n",
      "1  {'n_estimators': 52, 'max_depth': 19, 'learnin...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 285, 'singlet': 2591}\n",
      "100%|██████████| 10/10 [00:32<00:00,  3.23s/trial, best loss: -0.8930510748161998]\n",
      "sample1 Best parameters for tree: {'colsample_bytree': 0.7887484237761943, 'gamma': 0.15086289565996158, 'learning_rate': 0.38124401893968674, 'max_depth': 6, 'min_child_weight': 7, 'n_estimators': 46, 'reg_alpha': 0.6113427743178387, 'reg_lambda': 2.2310269019759854, 'scale_pos_weight': 48.142073704713354, 'subsample': 0.8514507862630176}\n",
      "sample1 Best tree score: {'loss': -0.8930510748161998, 'accuracy': 0.9618055555555556, 'status': 'ok', 'auroc': 0.9770814319034581, 'auprc': 0.8930510748161998}\n",
      "sample1 AUROC: 0.9551920341394026\n",
      "sample1 AUPRC: 0.8195769007552822\n",
      "sample1 Accuracy: 0.951304347826087\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample1   sample1  0.955192  0.819577  0.951304   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 47, 'max_depth': 7, 'learning...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:38<00:00,  3.89s/trial, best loss: -0.13024092800132572]\n",
      "sample1_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.5231234334461159, 'gamma': 0.9582148074182243, 'learning_rate': 0.20869092340139273, 'max_depth': 3, 'min_child_weight': 6, 'n_estimators': 93, 'reg_alpha': 0.14360801198798145, 'reg_lambda': 2.318391746516574, 'scale_pos_weight': 23.095783971545444, 'subsample': 0.635537698007432}\n",
      "sample1_neg_control_scrambled Best tree score: {'loss': -0.13024092800132572, 'accuracy': 0.8854166666666666, 'status': 'ok', 'auroc': 0.525707331913599, 'auprc': 0.13024092800132572}\n",
      "sample1_neg_control_scrambled AUROC: 0.49231186073291333\n",
      "sample1_neg_control_scrambled AUPRC: 0.11955131286303837\n",
      "sample1_neg_control_scrambled Accuracy: 0.8834782608695653\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample1                        sample1  0.955192  0.819577  0.951304   \n",
      "1  sample1  sample1_neg_control_scrambled  0.492312  0.119551  0.883478   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 47, 'max_depth': 7, 'learning...  \n",
      "1  {'n_estimators': 94, 'max_depth': 4, 'learning...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 285, 'singlet': 2591}\n",
      "100%|██████████| 10/10 [00:25<00:00,  2.58s/trial, best loss: -0.9162180725955319]\n",
      "sample1 Best parameters for tree: {'colsample_bytree': 0.676800291900681, 'gamma': 0.32517421933170726, 'learning_rate': 0.15745545009935058, 'max_depth': 16, 'min_child_weight': 6, 'n_estimators': 97, 'reg_alpha': 0.18885588985642154, 'reg_lambda': 1.9306049237351124, 'scale_pos_weight': 5.467776799039171, 'subsample': 0.8817060641128831}\n",
      "sample1 Best tree score: {'loss': -0.9162180725955319, 'accuracy': 0.953125, 'status': 'ok', 'auroc': 0.9862420985025183, 'auprc': 0.9162180725955319}\n",
      "sample1 AUROC: 0.9729052360631307\n",
      "sample1 AUPRC: 0.8708726827769447\n",
      "sample1 Accuracy: 0.9426086956521739\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample1   sample1  0.972905  0.870873  0.942609   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 98, 'max_depth': 17, 'learnin...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:28<00:00,  2.82s/trial, best loss: -0.14134482539672952]\n",
      "sample1_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.6201400912736421, 'gamma': 0.25847793505181665, 'learning_rate': 0.4075823243252942, 'max_depth': 0, 'min_child_weight': 6, 'n_estimators': 54, 'reg_alpha': 0.830541452637658, 'reg_lambda': 2.828225312727646, 'scale_pos_weight': 28.895374318835472, 'subsample': 0.5316206920129072}\n",
      "sample1_neg_control_scrambled Best tree score: {'loss': -0.14134482539672952, 'accuracy': 0.59375, 'status': 'ok', 'auroc': 0.5414596220802488, 'auprc': 0.14134482539672952}\n",
      "sample1_neg_control_scrambled AUROC: 0.4827609564451669\n",
      "sample1_neg_control_scrambled AUPRC: 0.09801101965932554\n",
      "sample1_neg_control_scrambled Accuracy: 0.5843478260869566\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample1                        sample1  0.972905  0.870873  0.942609   \n",
      "1  sample1  sample1_neg_control_scrambled  0.482761  0.098011  0.584348   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 98, 'max_depth': 17, 'learnin...  \n",
      "1  {'n_estimators': 55, 'max_depth': 1, 'learning...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 285, 'singlet': 2591}\n",
      "100%|██████████| 10/10 [00:23<00:00,  2.31s/trial, best loss: -0.832982509395265]\n",
      "sample1 Best parameters for tree: {'colsample_bytree': 0.6573174451065495, 'gamma': 0.9580078250298026, 'learning_rate': 0.3468700648515425, 'max_depth': 9, 'min_child_weight': 6, 'n_estimators': 80, 'reg_alpha': 0.5595039300689925, 'reg_lambda': 1.186252263634713, 'scale_pos_weight': 63.74141259544863, 'subsample': 0.576490041021029}\n",
      "sample1 Best tree score: {'loss': -0.832982509395265, 'accuracy': 0.9513888888888888, 'status': 'ok', 'auroc': 0.9679883716999628, 'auprc': 0.832982509395265}\n",
      "sample1 AUROC: 0.974903474903475\n",
      "sample1 AUPRC: 0.8520118255574882\n",
      "sample1 Accuracy: 0.9530434782608695\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample1   sample1  0.974903  0.852012  0.953043   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 81, 'max_depth': 10, 'learnin...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:37<00:00,  3.79s/trial, best loss: -0.1375496814064651]\n",
      "sample1_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.6745114579794532, 'gamma': 0.2658087802497519, 'learning_rate': 0.6919247056023231, 'max_depth': 17, 'min_child_weight': 4, 'n_estimators': 30, 'reg_alpha': 0.8480216988813162, 'reg_lambda': 1.9913049641478509, 'scale_pos_weight': 78.18027307303264, 'subsample': 0.7909695042397925}\n",
      "sample1_neg_control_scrambled Best tree score: {'loss': -0.1375496814064651, 'accuracy': 0.8524305555555556, 'status': 'ok', 'auroc': 0.5497752087347463, 'auprc': 0.1375496814064651}\n",
      "sample1_neg_control_scrambled AUROC: 0.49244733455259776\n",
      "sample1_neg_control_scrambled AUPRC: 0.10991890508385999\n",
      "sample1_neg_control_scrambled Accuracy: 0.8260869565217391\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample1                        sample1  0.974903  0.852012  0.953043   \n",
      "1  sample1  sample1_neg_control_scrambled  0.492447  0.109919  0.826087   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 81, 'max_depth': 10, 'learnin...  \n",
      "1  {'n_estimators': 31, 'max_depth': 18, 'learnin...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 261, 'singlet': 1896}\n",
      "100%|██████████| 10/10 [00:25<00:00,  2.51s/trial, best loss: -0.926313119116354]\n",
      "sample2 Best parameters for tree: {'colsample_bytree': 0.8140719704077648, 'gamma': 0.44319961921364615, 'learning_rate': 0.32604565126835255, 'max_depth': 8, 'min_child_weight': 8, 'n_estimators': 62, 'reg_alpha': 0.7815236688638751, 'reg_lambda': 2.2388711437048965, 'scale_pos_weight': 12.391715561321766, 'subsample': 0.6830524954834388}\n",
      "sample2 Best tree score: {'loss': -0.926313119116354, 'accuracy': 0.9652777777777778, 'status': 'ok', 'auroc': 0.9712550607287449, 'auprc': 0.926313119116354}\n",
      "sample2 AUROC: 0.9795007103714227\n",
      "sample2 AUPRC: 0.9475949528651899\n",
      "sample2 Accuracy: 0.9651972157772621\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample2   sample2  0.979501  0.947595  0.965197   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 63, 'max_depth': 9, 'learning...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:28<00:00,  2.87s/trial, best loss: -0.15463794667700226]\n",
      "sample2_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.9934997794353899, 'gamma': 0.19664584965392037, 'learning_rate': 0.7479403666398893, 'max_depth': 17, 'min_child_weight': 6, 'n_estimators': 17, 'reg_alpha': 0.3566833300858313, 'reg_lambda': 1.0733366303425596, 'scale_pos_weight': 35.50625512858694, 'subsample': 0.5242054046883757}\n",
      "sample2_neg_control_scrambled Best tree score: {'loss': -0.15463794667700226, 'accuracy': 0.7685185185185185, 'status': 'ok', 'auroc': 0.5898279352226721, 'auprc': 0.15463794667700226}\n",
      "sample2_neg_control_scrambled AUROC: 0.47665922468033284\n",
      "sample2_neg_control_scrambled AUPRC: 0.11884671649723248\n",
      "sample2_neg_control_scrambled Accuracy: 0.7610208816705336\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample2                        sample2  0.979501  0.947595  0.965197   \n",
      "1  sample2  sample2_neg_control_scrambled  0.476659  0.118847  0.761021   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 63, 'max_depth': 9, 'learning...  \n",
      "1  {'n_estimators': 18, 'max_depth': 18, 'learnin...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/488009245.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary = pd.concat([summary, dataset_summary_df])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 261, 'singlet': 1896}\n",
      "100%|██████████| 10/10 [00:21<00:00,  2.18s/trial, best loss: -0.9368184736063129]\n",
      "sample2 Best parameters for tree: {'colsample_bytree': 0.806967040988943, 'gamma': 0.8368856063118089, 'learning_rate': 0.1831550221167391, 'max_depth': 4, 'min_child_weight': 0, 'n_estimators': 66, 'reg_alpha': 0.9125520952126791, 'reg_lambda': 1.076755406162537, 'scale_pos_weight': 21.464024235615245, 'subsample': 0.8851540278700618}\n",
      "sample2 Best tree score: {'loss': -0.9368184736063129, 'accuracy': 0.9513888888888888, 'status': 'ok', 'auroc': 0.9816801619433199, 'auprc': 0.9368184736063129}\n",
      "sample2 AUROC: 0.9512380759082606\n",
      "sample2 AUPRC: 0.8907910368934304\n",
      "sample2 Accuracy: 0.9675174013921114\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample2   sample2  0.951238  0.890791  0.967517   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 67, 'max_depth': 5, 'learning...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/trial, best loss: -0.17411415101198147]\n",
      "sample2_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.5286254946497734, 'gamma': 0.3562120569458226, 'learning_rate': 0.6713553032885272, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 40, 'reg_alpha': 0.6048777942312696, 'reg_lambda': 2.410678766459106, 'scale_pos_weight': 98.5466150302882, 'subsample': 0.6632423554883657}\n",
      "sample2_neg_control_scrambled Best tree score: {'loss': -0.17411415101198147, 'accuracy': 0.7847222222222222, 'status': 'ok', 'auroc': 0.6000506072874494, 'auprc': 0.17411415101198147}\n",
      "sample2_neg_control_scrambled AUROC: 0.5420641363913132\n",
      "sample2_neg_control_scrambled AUPRC: 0.12384411838566318\n",
      "sample2_neg_control_scrambled Accuracy: 0.7749419953596288\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample2                        sample2  0.951238  0.890791  0.967517   \n",
      "1  sample2  sample2_neg_control_scrambled  0.542064  0.123844  0.774942   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 67, 'max_depth': 5, 'learning...  \n",
      "1  {'n_estimators': 41, 'max_depth': 13, 'learnin...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 261, 'singlet': 1896}\n",
      "100%|██████████| 10/10 [00:23<00:00,  2.33s/trial, best loss: -0.95426272935214]\n",
      "sample2 Best parameters for tree: {'colsample_bytree': 0.8750078709515443, 'gamma': 0.9254733209101096, 'learning_rate': 0.29138334758842394, 'max_depth': 2, 'min_child_weight': 6, 'n_estimators': 50, 'reg_alpha': 0.9230258438604936, 'reg_lambda': 1.1151340637511589, 'scale_pos_weight': 88.22568661712909, 'subsample': 0.7367020276982956}\n",
      "sample2 Best tree score: {'loss': -0.95426272935214, 'accuracy': 0.9675925925925926, 'status': 'ok', 'auroc': 0.9937246963562752, 'auprc': 0.95426272935214}\n",
      "sample2 AUROC: 0.9689466206616602\n",
      "sample2 AUPRC: 0.9028596097312782\n",
      "sample2 Accuracy: 0.9651972157772621\n",
      "   dataset condition     auroc    auprc  accuracy  \\\n",
      "0  sample2   sample2  0.968947  0.90286  0.965197   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 51, 'max_depth': 3, 'learning...  \n",
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:28<00:00,  2.84s/trial, best loss: -0.14315306663621097]\n",
      "sample2_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.7006032595534895, 'gamma': 0.2118167184067639, 'learning_rate': 0.4438432452119713, 'max_depth': 16, 'min_child_weight': 6, 'n_estimators': 52, 'reg_alpha': 0.2065573631852996, 'reg_lambda': 2.891244625046811, 'scale_pos_weight': 12.857939547057784, 'subsample': 0.6532411019570743}\n",
      "sample2_neg_control_scrambled Best tree score: {'loss': -0.14315306663621097, 'accuracy': 0.8333333333333334, 'status': 'ok', 'auroc': 0.479251012145749, 'auprc': 0.14315306663621097}\n",
      "sample2_neg_control_scrambled AUROC: 0.5591637913537648\n",
      "sample2_neg_control_scrambled AUPRC: 0.15051727933428208\n",
      "sample2_neg_control_scrambled Accuracy: 0.8468677494199536\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample2                        sample2  0.968947  0.902860  0.965197   \n",
      "1  sample2  sample2_neg_control_scrambled  0.559164  0.150517  0.846868   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 51, 'max_depth': 3, 'learning...  \n",
      "1  {'n_estimators': 53, 'max_depth': 17, 'learnin...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 261, 'singlet': 1896}\n",
      "100%|██████████| 10/10 [00:23<00:00,  2.38s/trial, best loss: -0.8879428973665654]\n",
      "sample2 Best parameters for tree: {'colsample_bytree': 0.987318035285217, 'gamma': 0.25103592394494123, 'learning_rate': 0.3885837872347381, 'max_depth': 16, 'min_child_weight': 1, 'n_estimators': 95, 'reg_alpha': 0.7422147021423608, 'reg_lambda': 1.328614230233698, 'scale_pos_weight': 67.37019739370417, 'subsample': 0.8357233601636362}\n",
      "sample2 Best tree score: {'loss': -0.8879428973665654, 'accuracy': 0.9699074074074074, 'status': 'ok', 'auroc': 0.9441801619433198, 'auprc': 0.8879428973665654}\n",
      "sample2 AUROC: 0.9872133143900954\n",
      "sample2 AUPRC: 0.951401349144064\n",
      "sample2 Accuracy: 0.974477958236659\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample2   sample2  0.987213  0.951401  0.974478   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 96, 'max_depth': 17, 'learnin...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.39s/trial, best loss: -0.1798196146730927]\n",
      "sample2_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.744928161789364, 'gamma': 0.3015320646245827, 'learning_rate': 0.1311273156125351, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 84, 'reg_alpha': 0.5508193807638289, 'reg_lambda': 1.4102277269945196, 'scale_pos_weight': 94.27085668119365, 'subsample': 0.5974632088588407}\n",
      "sample2_neg_control_scrambled Best tree score: {'loss': -0.1798196146730927, 'accuracy': 0.7986111111111112, 'status': 'ok', 'auroc': 0.5671558704453441, 'auprc': 0.1798196146730927}\n",
      "sample2_neg_control_scrambled AUROC: 0.49436776943373245\n",
      "sample2_neg_control_scrambled AUPRC: 0.13604712624015425\n",
      "sample2_neg_control_scrambled Accuracy: 0.8074245939675174\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample2                        sample2  0.987213  0.951401  0.974478   \n",
      "1  sample2  sample2_neg_control_scrambled  0.494368  0.136047  0.807425   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 96, 'max_depth': 17, 'learnin...  \n",
      "1  {'n_estimators': 85, 'max_depth': 5, 'learning...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 261, 'singlet': 1896}\n",
      "100%|██████████| 10/10 [00:26<00:00,  2.69s/trial, best loss: -0.9445908944030812]\n",
      "sample2 Best parameters for tree: {'colsample_bytree': 0.82271956789877, 'gamma': 0.9726585618513608, 'learning_rate': 0.1342252310667848, 'max_depth': 17, 'min_child_weight': 3, 'n_estimators': 98, 'reg_alpha': 0.6145021989078341, 'reg_lambda': 1.6067853302136184, 'scale_pos_weight': 6.77476602619271, 'subsample': 0.5349269844265494}\n",
      "sample2 Best tree score: {'loss': -0.9445908944030812, 'accuracy': 0.9560185185185185, 'status': 'ok', 'auroc': 0.9874493927125506, 'auprc': 0.9445908944030812}\n",
      "sample2 AUROC: 0.9474832555307489\n",
      "sample2 AUPRC: 0.8472178478028914\n",
      "sample2 Accuracy: 0.9535962877030162\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample2   sample2  0.947483  0.847218  0.953596   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 99, 'max_depth': 18, 'learnin...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:41<00:00,  4.18s/trial, best loss: -0.1404148640070899]\n",
      "sample2_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.9719548582296155, 'gamma': 0.597704203945928, 'learning_rate': 0.49164726923185703, 'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 86, 'reg_alpha': 0.6310371165951536, 'reg_lambda': 1.6026460854630824, 'scale_pos_weight': 79.01028781908917, 'subsample': 0.8344608637643643}\n",
      "sample2_neg_control_scrambled Best tree score: {'loss': -0.1404148640070899, 'accuracy': 0.8194444444444444, 'status': 'ok', 'auroc': 0.5221659919028341, 'auprc': 0.1404148640070899}\n",
      "sample2_neg_control_scrambled AUROC: 0.5824030850416074\n",
      "sample2_neg_control_scrambled AUPRC: 0.15346285795183107\n",
      "sample2_neg_control_scrambled Accuracy: 0.839907192575406\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample2                        sample2  0.947483  0.847218  0.953596   \n",
      "1  sample2  sample2_neg_control_scrambled  0.582403  0.153463  0.839907   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 99, 'max_depth': 18, 'learnin...  \n",
      "1  {'n_estimators': 87, 'max_depth': 8, 'learning...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 261, 'singlet': 1896}\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.24s/trial, best loss: -0.9544342632368699]\n",
      "sample2 Best parameters for tree: {'colsample_bytree': 0.7158875604797696, 'gamma': 0.8815167075063731, 'learning_rate': 0.13777137740713494, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 87, 'reg_alpha': 0.7971853021350416, 'reg_lambda': 2.103107018755135, 'scale_pos_weight': 90.50443142668021, 'subsample': 0.5992981252800644}\n",
      "sample2 Best tree score: {'loss': -0.9544342632368699, 'accuracy': 0.9745370370370371, 'status': 'ok', 'auroc': 0.9902327935222672, 'auprc': 0.9544342632368699}\n",
      "sample2 AUROC: 0.9963974020702253\n",
      "sample2 AUPRC: 0.9773131321773181\n",
      "sample2 Accuracy: 0.9837587006960556\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample2   sample2  0.996397  0.977313  0.983759   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 88, 'max_depth': 6, 'learning...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:40<00:00,  4.05s/trial, best loss: -0.14126781154051307]\n",
      "sample2_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.881349782221059, 'gamma': 0.4480606297159974, 'learning_rate': 0.4865646463394279, 'max_depth': 14, 'min_child_weight': 0, 'n_estimators': 17, 'reg_alpha': 0.3974270171764631, 'reg_lambda': 2.927503898818969, 'scale_pos_weight': 88.43332010042704, 'subsample': 0.7873575890233333}\n",
      "sample2_neg_control_scrambled Best tree score: {'loss': -0.14126781154051307, 'accuracy': 0.8032407407407407, 'status': 'ok', 'auroc': 0.48537449392712556, 'auprc': 0.14126781154051307}\n",
      "sample2_neg_control_scrambled AUROC: 0.5328800487111833\n",
      "sample2_neg_control_scrambled AUPRC: 0.15932619748030732\n",
      "sample2_neg_control_scrambled Accuracy: 0.8051044083526682\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample2                        sample2  0.996397  0.977313  0.983759   \n",
      "1  sample2  sample2_neg_control_scrambled  0.532880  0.159326  0.805104   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 88, 'max_depth': 6, 'learning...  \n",
      "1  {'n_estimators': 18, 'max_depth': 15, 'learnin...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 261, 'singlet': 1896}\n",
      "100%|██████████| 10/10 [00:27<00:00,  2.79s/trial, best loss: -0.9224606661430149]\n",
      "sample2 Best parameters for tree: {'colsample_bytree': 0.8230726231317564, 'gamma': 0.6368561243624619, 'learning_rate': 0.13903414563295724, 'max_depth': 16, 'min_child_weight': 5, 'n_estimators': 64, 'reg_alpha': 0.8353332182272868, 'reg_lambda': 2.4288540911388723, 'scale_pos_weight': 56.25946034793464, 'subsample': 0.8901154372889962}\n",
      "sample2 Best tree score: {'loss': -0.9224606661430149, 'accuracy': 0.9675925925925926, 'status': 'ok', 'auroc': 0.9773785425101215, 'auprc': 0.9224606661430149}\n",
      "sample2 AUROC: 0.9817333062715649\n",
      "sample2 AUPRC: 0.9123555419754481\n",
      "sample2 Accuracy: 0.9489559164733179\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample2   sample2  0.981733  0.912356  0.948956   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 65, 'max_depth': 17, 'learnin...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.42s/trial, best loss: -0.18445355711566686]\n",
      "sample2_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.7874957045709474, 'gamma': 0.13414101104123627, 'learning_rate': 0.7167553861916275, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 26, 'reg_alpha': 0.9137767953408962, 'reg_lambda': 1.4045006951096042, 'scale_pos_weight': 67.89650618391099, 'subsample': 0.9088509300494692}\n",
      "sample2_neg_control_scrambled Best tree score: {'loss': -0.18445355711566686, 'accuracy': 0.7824074074074074, 'status': 'ok', 'auroc': 0.5732793522267207, 'auprc': 0.18445355711566686}\n",
      "sample2_neg_control_scrambled AUROC: 0.5418104323117515\n",
      "sample2_neg_control_scrambled AUPRC: 0.136032566567042\n",
      "sample2_neg_control_scrambled Accuracy: 0.8004640371229699\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample2                        sample2  0.981733  0.912356  0.948956   \n",
      "1  sample2  sample2_neg_control_scrambled  0.541810  0.136033  0.800464   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 65, 'max_depth': 17, 'learnin...  \n",
      "1  {'n_estimators': 27, 'max_depth': 6, 'learning...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 261, 'singlet': 1896}\n",
      "100%|██████████| 10/10 [00:18<00:00,  1.83s/trial, best loss: -0.9299432849492152]\n",
      "sample2 Best parameters for tree: {'colsample_bytree': 0.582534529812397, 'gamma': 0.8408035245530273, 'learning_rate': 0.18452501820097728, 'max_depth': 7, 'min_child_weight': 8, 'n_estimators': 62, 'reg_alpha': 0.14254561926527254, 'reg_lambda': 1.9871989625230488, 'scale_pos_weight': 42.59481391796585, 'subsample': 0.9112597342632384}\n",
      "sample2 Best tree score: {'loss': -0.9299432849492152, 'accuracy': 0.9699074074074074, 'status': 'ok', 'auroc': 0.9832489878542511, 'auprc': 0.9299432849492152}\n",
      "sample2 AUROC: 0.9952303633042419\n",
      "sample2 AUPRC: 0.9758242697233122\n",
      "sample2 Accuracy: 0.9814385150812065\n",
      "   dataset condition    auroc     auprc  accuracy  \\\n",
      "0  sample2   sample2  0.99523  0.975824  0.981439   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 63, 'max_depth': 8, 'learning...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.77s/trial, best loss: -0.14152404407207309]\n",
      "sample2_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.5281709969023181, 'gamma': 0.22913329149507655, 'learning_rate': 0.9425257121048617, 'max_depth': 17, 'min_child_weight': 2, 'n_estimators': 34, 'reg_alpha': 0.34423491037938747, 'reg_lambda': 2.907516754428174, 'scale_pos_weight': 28.284891344109294, 'subsample': 0.6129561585224256}\n",
      "sample2_neg_control_scrambled Best tree score: {'loss': -0.14152404407207309, 'accuracy': 0.8101851851851852, 'status': 'ok', 'auroc': 0.5288461538461539, 'auprc': 0.14152404407207309}\n",
      "sample2_neg_control_scrambled AUROC: 0.4786381165009133\n",
      "sample2_neg_control_scrambled AUPRC: 0.11353233812924525\n",
      "sample2_neg_control_scrambled Accuracy: 0.7726218097447796\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample2                        sample2  0.995230  0.975824  0.981439   \n",
      "1  sample2  sample2_neg_control_scrambled  0.478638  0.113532  0.772622   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 63, 'max_depth': 8, 'learning...  \n",
      "1  {'n_estimators': 35, 'max_depth': 18, 'learnin...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 261, 'singlet': 1896}\n",
      "100%|██████████| 10/10 [00:23<00:00,  2.37s/trial, best loss: -0.9493632129095967]\n",
      "sample2 Best parameters for tree: {'colsample_bytree': 0.6676881516861497, 'gamma': 0.168631584984889, 'learning_rate': 0.3107215867128714, 'max_depth': 10, 'min_child_weight': 4, 'n_estimators': 54, 'reg_alpha': 0.8320536528343095, 'reg_lambda': 1.6847100981555083, 'scale_pos_weight': 36.88551442756622, 'subsample': 0.7691799574510481}\n",
      "sample2 Best tree score: {'loss': -0.9493632129095967, 'accuracy': 0.9837962962962963, 'status': 'ok', 'auroc': 0.9739372469635628, 'auprc': 0.9493632129095967}\n",
      "sample2 AUROC: 0.9652425411000609\n",
      "sample2 AUPRC: 0.9211667914314118\n",
      "sample2 Accuracy: 0.9721577726218097\n",
      "   dataset condition     auroc     auprc  accuracy  \\\n",
      "0  sample2   sample2  0.965243  0.921167  0.972158   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 55, 'max_depth': 11, 'learnin...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:34<00:00,  3.43s/trial, best loss: -0.15917271045773007]\n",
      "sample2_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.9095138716908135, 'gamma': 0.3330104387324479, 'learning_rate': 0.18181120665111203, 'max_depth': 16, 'min_child_weight': 6, 'n_estimators': 60, 'reg_alpha': 0.7567296828327666, 'reg_lambda': 2.3549326646900397, 'scale_pos_weight': 60.76330849730732, 'subsample': 0.8692821119493064}\n",
      "sample2_neg_control_scrambled Best tree score: {'loss': -0.15917271045773007, 'accuracy': 0.8611111111111112, 'status': 'ok', 'auroc': 0.581174089068826, 'auprc': 0.15917271045773007}\n",
      "sample2_neg_control_scrambled AUROC: 0.43865435356200533\n",
      "sample2_neg_control_scrambled AUPRC: 0.10666243604007654\n",
      "sample2_neg_control_scrambled Accuracy: 0.8631090487238979\n",
      "   dataset                      condition     auroc     auprc  accuracy  \\\n",
      "0  sample2                        sample2  0.965243  0.921167  0.972158   \n",
      "1  sample2  sample2_neg_control_scrambled  0.438654  0.106662  0.863109   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 55, 'max_depth': 11, 'learnin...  \n",
      "1  {'n_estimators': 61, 'max_depth': 17, 'learnin...  \n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 261, 'singlet': 1896}\n",
      "100%|██████████| 10/10 [00:30<00:00,  3.09s/trial, best loss: -0.9641824706063725]\n",
      "sample2 Best parameters for tree: {'colsample_bytree': 0.8509299112001946, 'gamma': 0.6753051308398509, 'learning_rate': 0.21215740774290412, 'max_depth': 10, 'min_child_weight': 4, 'n_estimators': 70, 'reg_alpha': 0.027602410263726007, 'reg_lambda': 2.7416944176417934, 'scale_pos_weight': 98.17516203570091, 'subsample': 0.8045695617826754}\n",
      "sample2 Best tree score: {'loss': -0.9641824706063725, 'accuracy': 0.9814814814814815, 'status': 'ok', 'auroc': 0.9917004048582996, 'auprc': 0.9641824706063725}\n",
      "sample2 AUROC: 0.9794499695555106\n",
      "sample2 AUPRC: 0.9324168485507528\n",
      "sample2 Accuracy: 0.9698375870069605\n",
      "   dataset condition    auroc     auprc  accuracy  \\\n",
      "0  sample2   sample2  0.97945  0.932417  0.969838   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 71, 'max_depth': 11, 'learnin...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/29195845.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:39<00:00,  3.93s/trial, best loss: -0.1822437525965624]\n",
      "sample2_neg_control_scrambled Best parameters for tree: {'colsample_bytree': 0.8230658875420314, 'gamma': 0.2237049696604586, 'learning_rate': 0.4260353490107853, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 78, 'reg_alpha': 0.6802617685634006, 'reg_lambda': 1.7416922659991554, 'scale_pos_weight': 54.6933584627515, 'subsample': 0.9090297901255493}\n",
      "sample2_neg_control_scrambled Best tree score: {'loss': -0.1822437525965624, 'accuracy': 0.8425925925925926, 'status': 'ok', 'auroc': 0.48248987854251013, 'auprc': 0.1822437525965624}\n",
      "sample2_neg_control_scrambled AUROC: 0.5020296326364928\n",
      "sample2_neg_control_scrambled AUPRC: 0.1477837243421046\n",
      "sample2_neg_control_scrambled Accuracy: 0.8352668213457076\n",
      "   dataset                      condition    auroc     auprc  accuracy  \\\n",
      "0  sample2                        sample2  0.97945  0.932417  0.969838   \n",
      "1  sample2  sample2_neg_control_scrambled  0.50203  0.147784  0.835267   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 71, 'max_depth': 11, 'learnin...  \n",
      "1  {'n_estimators': 79, 'max_depth': 5, 'learning...  \n"
     ]
    }
   ],
   "source": [
    "### different datasets\n",
    "np.random.seed(23)\n",
    "\n",
    "dataset_main = \"TREX_minusCluster\"\n",
    "\n",
    "dataset_list = [\"sample1\", \"sample2\"]\n",
    "\n",
    "data_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/\", dataset_main)\n",
    "results_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/predictions/\"\n",
    "summaries_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/datasetSummaries/\"\n",
    "classifiers_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/classifiers/\", dataset_main)\n",
    "\n",
    "for dataset in dataset_list:\n",
    "\n",
    "    summary = pd.DataFrame(columns = [\"dataset\", \"condition\", \"auroc\", \"auprc\", \"accuracy\", \"best_params\"])\n",
    "\n",
    "    for count in range(10):\n",
    "        np.random.seed(count)\n",
    "        dataset_summary_df = main(dataset)\n",
    "        summary = pd.concat([summary, dataset_summary_df])\n",
    "\n",
    "    summary.to_csv(f\"{summaries_dir}/{dataset_main}/{dataset}.csv\", index = False)\n",
    "\n",
    "#summary.to_csv(os.path.join(summaries_dir, dataset_main, f\"{dataset_main}.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset):\n",
    "    if dataset.startswith(\"0\"): # denotes variable doublet rate datasets, where the dataset name is the doublet rate\n",
    "        counts_dir = os.path.join(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier/FM01/variable_doublet_rates_2\", dataset)\n",
    "        labels_dir = os.path.join(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier/FM01/\")\n",
    "    else:\n",
    "        counts_dir = os.path.join(data_dir, \"10X\", dataset)\n",
    "        labels_dir = os.path.join(data_dir, \"10X\", dataset)\n",
    "\n",
    "        #counts_dir = os.path.join(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier/s1s2\", dataset, \"10X_doublets_2/\")\n",
    "        #labels_dir = os.path.join(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier/s1s2\", dataset)\n",
    "\n",
    "\n",
    "    summary_df = pd.DataFrame(columns = [\"dataset\", \"condition\", \"auroc\", \"auprc\", \"accuracy\", \"best_params\"])\n",
    "\n",
    "    features, labels_encoded, barcodes_1, matrix_array, genes = load_and_preprocess_data(counts_dir, labels_dir)\n",
    "    #FM01_dict = use_FM01_classifier(features, labels_encoded, barcodes_1, results_dir, classifiers_dir)\n",
    "    #summary_df = pd.concat([summary_df, pd.DataFrame([FM01_dict])], ignore_index=True)\n",
    "    #print(summary_df)\n",
    "    self_dict = train_classifier(features, labels_encoded, barcodes_1, dataset)\n",
    "    summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n",
    "    print(summary_df)\n",
    "    scrambled_dict = negative_controls(features, labels_encoded, barcodes_1, dataset, matrix_array, genes)\n",
    "    #singlets_dict, doublets_dict, scrambled_dict = negative_controls(features, labels_encoded, barcodes_1, dataset, matrix_array, genes)\n",
    "    #summary_df = pd.concat([summary_df, pd.DataFrame([singlets_dict])], ignore_index=True)\n",
    "    #summary_df = pd.concat([summary_df, pd.DataFrame([doublets_dict])], ignore_index=True)\n",
    "    #summary_df = pd.concat([summary_df, pd.DataFrame([shuffled_dict])], ignore_index=True)\n",
    "    summary_df = pd.concat([summary_df, pd.DataFrame([scrambled_dict])], ignore_index=True)\n",
    "    print(summary_df)\n",
    "\n",
    "    return summary_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(counts_dir, labels_dir):\n",
    "    os.chdir(counts_dir)\n",
    "\n",
    "    # Read the .mtx file\n",
    "    matrix = scipy.io.mmread(\"matrix.mtx\")\n",
    "    matrix = matrix.transpose()\n",
    "    matrix_array = matrix.toarray()\n",
    "\n",
    "    # Read the features and barcodes files\n",
    "    genes = pd.read_csv(\"features.tsv.gz\", header=None, sep=\"\\t\")\n",
    "    genes_list = genes.index.tolist()\n",
    "    first_column = genes.columns[0]\n",
    "    genes = genes.set_index(first_column) #this is to ensure the anndata object is created correctly and that there are no extra columns in the features or barcodes dfs\n",
    "    barcodes = pd.read_csv(\"barcodes.tsv.gz\", header=None, sep=\"\\t\")\n",
    "    first_column = barcodes.columns[0]\n",
    "    barcodes = barcodes.set_index(first_column)\n",
    "\n",
    "    # Create the AnnData object\n",
    "    data = anndata.AnnData(X=matrix_array, var=genes_list, obs=barcodes)\n",
    "\n",
    "    # getting singlet and multiplet labels\n",
    "    os.chdir(labels_dir)\n",
    "    labels_df = pd.read_csv(f'labels_2.csv') #for \"variable doublet rates\", indicate _{dataset} here\n",
    "\n",
    "    ############## Preprocessing data\n",
    "    print(data.obs.columns)  # Check columns in data.obs\n",
    "    print(labels_df.columns) \n",
    "\n",
    "    # combining features matrix and labels\n",
    "    data.obs.index = data.obs.index.rename('barcode')\n",
    "    merged = data.obs.merge(labels_df, on='barcode', how='inner')\n",
    "    #print(merged.head()) #checking what the merged looks like\n",
    "\n",
    "    # Extract the features matrix and labels\n",
    "    features = data.X\n",
    "    labels = merged['label'].values\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    print(dict(zip(unique_labels, counts))) #checking the number of singlets and multiplets\n",
    "\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_encoded = label_encoder.fit_transform(labels)\n",
    "    labels_encoded = 1 - labels_encoded #switching the labels so that 1s are multiplets and 0s are singlets, so correclty identified 1s are considered true positives\n",
    "    counts = np.bincount(labels_encoded)\n",
    "    #print(counts) #checking that the number of singlets and multiplets is the same as above\n",
    "\n",
    "    barcodes_1 = data.obs.index.to_numpy() #getting the barcodes for the features matrix to identify the cells that are being classified\n",
    "\n",
    "    return features, labels_encoded, barcodes_1, matrix_array, genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(features, labels_encoded, barcodes_1, condition):\n",
    "    # split into training, testing, and validation sets\n",
    "    X_train, X_test_temp, y_train, y_test_temp, barcodes_train, barcodes_test = train_test_split(features, labels_encoded, barcodes_1, test_size=0.4, random_state=count, shuffle=True, stratify=labels_encoded) # 40% test set, 60% training set\n",
    "    X_test, X_valid, y_test, y_valid, barcodes_test, barcodes_valid = train_test_split(X_test_temp, y_test_temp, barcodes_test, test_size=0.5, random_state=count, shuffle=True, stratify=y_test_temp) # Split 50% of the test set into a validation set\n",
    "    #print the first 10 rows of the training set\n",
    "    #print(X_train[:10])\n",
    "    #print the first 10 rows of the test_temp set\n",
    "    #print(X_test_temp[:10])\n",
    "\n",
    "\n",
    "    # Define the hyperparameter space\n",
    "    space_tree = {\n",
    "        'n_estimators': hp.choice('n_estimators', range(1, 100)),\n",
    "        'max_depth': hp.choice('max_depth', range(1, 20)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 1),\n",
    "        'objective': 'binary:logistic',\n",
    "        'min_child_weight': hp.choice('min_child_weight', range(1, 10)),\n",
    "        'gamma': hp.uniform('gamma', 0.1, 1.0),\n",
    "        'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "        'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 1.0, 3.0),\n",
    "        'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 100),\n",
    "        'booster': 'gbtree'\n",
    "    }\n",
    "\n",
    "    # Define objective function\n",
    "    def objective(params):\n",
    "        bst = XGBClassifier(**params, random_state=count)\n",
    "        bst.fit(X_train, y_train)\n",
    "        preds = bst.predict(X_valid)\n",
    "        preds_proba = bst.predict_proba(X_valid)[:, 1]\n",
    "        accuracy = accuracy_score(y_valid, preds)\n",
    "        auroc = roc_auc_score(y_valid, preds_proba)  # Calculate AUROC\n",
    "        auprc = average_precision_score(y_valid, preds_proba)  # Calculate AUPRC\n",
    "        return {'loss': -auprc, 'accuracy': accuracy, 'status': STATUS_OK, 'auroc': auroc, 'auprc': auprc}\n",
    "\n",
    "    # Run the hyperparameter optimization\n",
    "    trials_tree = Trials()\n",
    "    best_tree = fmin(fn=objective, space=space_tree, algo=tpe.suggest, max_evals=10, trials=trials_tree)\n",
    "    print(f\"{condition} Best parameters for tree: {best_tree}\")\n",
    "\n",
    "    # Summary of the success of the hyperparameter optimization\n",
    "    best_tree_score = min(trials_tree.results, key=lambda x: x['loss'])\n",
    "    print(f\"{condition} Best tree score: {best_tree_score}\")\n",
    "\n",
    "    # Adjusting the hyperparameters\n",
    "    best_params_tree = {\n",
    "        'n_estimators': best_tree['n_estimators'] + 1,  # +1 because hp.choice returns an index\n",
    "        'max_depth': best_tree['max_depth'] + 1,        # +1 for the same reason\n",
    "        'learning_rate': best_tree['learning_rate'],\n",
    "        'objective': 'binary:logistic',\n",
    "        'min_child_weight': best_tree['min_child_weight'] + 1,  # Adjust if needed\n",
    "        'gamma': best_tree['gamma'],\n",
    "        'subsample': best_tree['subsample'],\n",
    "        'reg_alpha': best_tree['reg_alpha'],\n",
    "        'reg_lambda': best_tree['reg_lambda'],\n",
    "        'scale_pos_weight': best_tree['scale_pos_weight'],\n",
    "        'booster': 'gbtree'\n",
    "    }\n",
    "\n",
    "    # Retrain the classifier with the best hyperparameters\n",
    "    bst_best = XGBClassifier(**best_params_tree, random_state=23)\n",
    "    if condition == dataset:\n",
    "        dump(bst_best, classifiers_dir + f'/{dataset}_{count}_unfit.joblib') #saving unfit classifier\n",
    "    bst_best.fit(X_train, y_train)\n",
    "    if condition == dataset:\n",
    "        dump(bst_best, classifiers_dir + f'/{dataset}_{count}_fit.joblib') #saving fit classifier\n",
    "\n",
    "    preds_proba = bst_best.predict_proba(X_test)[:,1]  # Get probabilities of the positive class (multiplets- 1)\n",
    "    auroc = roc_auc_score(y_test, preds_proba) # Calculate AUROC\n",
    "    print(f\"{condition} AUROC: {auroc}\")\n",
    "    auprc = average_precision_score(y_test, preds_proba) # Calculate AUPRC\n",
    "    print(f\"{condition} AUPRC: {auprc}\")\n",
    "    y_preds = bst_best.predict(X_test) # Predict labels on the test set\n",
    "    accuracy = accuracy_score(y_test, y_preds) # Calculate accuracy\n",
    "    print(f\"{condition} Accuracy: {accuracy}\")\n",
    "    results = pd.DataFrame({\n",
    "        'barcode': barcodes_test,\n",
    "        'prediction probability': preds_proba,\n",
    "        'predicted': y_preds,\n",
    "        'actual': y_test\n",
    "    })\n",
    "    results.to_csv(os.path.join(results_dir, dataset_main, f\"{condition}_predicted_actual.csv\"))\n",
    "\n",
    "    summary_dict = {\"dataset\": dataset, \"condition\": condition, \"auroc\": auroc, \"auprc\": auprc, \"accuracy\": accuracy, \"best_params\": best_params_tree}\n",
    "\n",
    "    return summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_controls(features, labels_encoded, barcodes_1, dataset, matrix_array, genes):\n",
    "    total_cells = len(features)\n",
    "    num_doublets = int((len(features)*0.1)/0.9)\n",
    "    num_singlets = int(total_cells - num_doublets)\n",
    "\n",
    "    # ############### singlets only ###############\n",
    "\n",
    "    # # selecting only singlets as a control\n",
    "    # features_singlets = features[:(num_singlets), :] #singlets always first in the features matrix\n",
    "    # # creating fake doublets from those singlets\n",
    "    # labels_singlets = np.zeros(num_singlets)\n",
    "    # fakedoubletsforsinglets = int((len(features_singlets)*0.1)/0.9)\n",
    "    # # making 10% of the singlets into fake doublets\n",
    "    # labels_singlets[0:fakedoubletsforsinglets] = 1 \n",
    "\n",
    "    # barcodes_singlets = barcodes_1[:num_singlets]\n",
    "\n",
    "    # singlets_dict = train_classifier(features_singlets, labels_singlets, barcodes_singlets, f\"{dataset}_neg_control_singlets\")\n",
    "    \n",
    "    # ############### doublets only ###############\n",
    "    \n",
    "    # # selecting only doublets as a control\n",
    "    # features_doublets = features[-num_doublets:, :] #doublets always last in the features matrix\n",
    "    # # creating fake singlets from those doublets\n",
    "    # labels_doublets = np.ones(num_doublets)\n",
    "    # fakesingletsfordoublets = int(num_doublets - ((len(features_doublets)*0.1)/0.9))\n",
    "    # # making 90% of the doublets into fake singlets\n",
    "    # labels_doublets[0:fakesingletsfordoublets] = 0\n",
    "\n",
    "    # barcodes_doublets = barcodes_1[-num_doublets:]\n",
    "    \n",
    "    # doublets_dict = train_classifier(features_doublets, labels_doublets, barcodes_doublets, f\"{dataset}_neg_control_doublets\")\n",
    " \n",
    "    ############### shuffling features ###############\n",
    "\n",
    "    # shuffled_indices = np.random.permutation(matrix_array.shape[1]) # Generate a shuffled index\n",
    "    # matrix_array_shuffled = matrix_array[:, shuffled_indices] # Shuffle the columns of the matrix\n",
    "    # genes_shuffled = genes.iloc[shuffled_indices] # Reorder the features DataFrame to match the new column order (NOTE: this doesnt get used here)\n",
    "\n",
    "    # shuffled_data = anndata.AnnData(X=matrix_array_shuffled, var=genes_shuffled, obs=barcodes_1) #(NOTE: this doesnt get used here-- should i use it? probably unnecessary to specify gene names)\n",
    "\n",
    "    # features_shuffled = shuffled_data.X\n",
    "\n",
    "    # shuffled_dict = train_classifier(features_shuffled, labels_encoded, barcodes_1, f\"{dataset}_shuffled\")\n",
    "\n",
    "    ############### scrambling features ###############\n",
    "\n",
    "    flattened_matrix = matrix_array.flatten()\n",
    "    np.random.shuffle(flattened_matrix)\n",
    "    scrambled_matrix_array = flattened_matrix.reshape(matrix_array.shape)\n",
    "\n",
    "    features_scrambled = scrambled_matrix_array\n",
    "\n",
    "    scrambled_dict = train_classifier(features_scrambled, labels_encoded, barcodes_1, f\"{dataset}_neg_control_scrambled\")\n",
    "\n",
    "    return scrambled_dict #(removed shuffled_dict 20240513, singlets_dict, doublets_dict on 20240515)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"s1nc_positiveControl\"\n",
    "condition = f\"{dataset}_standard\"\n",
    "results_dir = \"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier/results/\"\n",
    "classifiers_dir = \"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier/classifiers/\"\n",
    "\n",
    "counts_dir = os.path.join(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier\", dataset, \"10X_doublets_2/\")\n",
    "#counts_dir = os.path.join(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier/FM01/variable_doublet_rates\", dataset)\n",
    "labels_dir = os.path.join(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier\", dataset)\n",
    "#labels_dir = os.path.join(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/classifier/FM01/\")\n",
    "\n",
    "summary_df = pd.DataFrame(columns = [\"dataset\", \"condition\", \"auroc\", \"auprc\", \"accuracy\", \"best_params\"])\n",
    "\n",
    "features, labels_encoded, barcodes_1, matrix_array, genes = load_and_preprocess_data(counts_dir, labels_dir)\n",
    "#FM01_dict = use_FM01_classifier(features, labels_encoded, barcodes_1, results_dir, classifiers_dir)\n",
    "#summary_df = pd.concat([summary_df, pd.DataFrame([FM01_dict])], ignore_index=True)\n",
    "#print(summary_df)\n",
    "self_dict = train_classifier(features, labels_encoded, barcodes_1, condition)\n",
    "summary_df = pd.concat([summary_df, pd.DataFrame([self_dict])], ignore_index=True)\n",
    "print(summary_df)\n",
    "singlets_dict, doublets_dict, shuffled_dict, scrambled_dict = negative_controls(features, labels_encoded, barcodes_1, condition, matrix_array, genes)\n",
    "summary_df = pd.concat([summary_df, pd.DataFrame([singlets_dict])], ignore_index=True)\n",
    "summary_df = pd.concat([summary_df, pd.DataFrame([doublets_dict])], ignore_index=True)\n",
    "summary_df = pd.concat([summary_df, pd.DataFrame([shuffled_dict])], ignore_index=True)\n",
    "summary_df = pd.concat([summary_df, pd.DataFrame([scrambled_dict])], ignore_index=True)\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### writing a function to scramble the data \n",
    "\n",
    "def negative_controls(features, labels_encoded, barcodes_1, dataset, matrix_array, genes):\n",
    "    flattened_matrix = matrix_array.flatten()\n",
    "    np.random.shuffle(flattened_matrix)\n",
    "    scrambled_matrix_array = flattened_matrix.reshape(matrix_array.shape)\n",
    "\n",
    "    features_scrambled = scrambled_matrix_array\n",
    "\n",
    "    scrambled_dict = train_classifier(features_scrambled, labels_encoded, barcodes_1, f\"{dataset}_neg_control_scrambled\")\n",
    "\n",
    "    return scrambled_dict #(removed shuffled_dict 20240513, singlets_dict, doublets_dict on 20240515)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## writing a function to use the classifier on a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/classifiers/FateMap\n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 489, 'singlet': 4401}\n",
      "AUROC: 0.5199415544617347\n",
      "AUPRC: 0.1019402802787604\n",
      "Accuracy: 0.12249488752556237\n",
      "AUROC: 0.5090184467278073\n",
      "AUPRC: 0.10371919621402345\n",
      "Accuracy: 0.1310838445807771\n",
      "AUROC: 0.5269368506599866\n",
      "AUPRC: 0.1111185799670817\n",
      "Accuracy: 0.4768916155419223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/827897467.py:42: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_scrambled = pd.concat([summary_scrambled, pd.DataFrame([summary_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.5090474882776689\n",
      "AUPRC: 0.10551955713110982\n",
      "Accuracy: 0.12740286298568507\n",
      "AUROC: 0.512489725099659\n",
      "AUPRC: 0.10460181871601035\n",
      "Accuracy: 0.1554192229038855\n",
      "AUROC: 0.49951279895952255\n",
      "AUPRC: 0.10010035110362053\n",
      "Accuracy: 0.17873210633946832\n",
      "AUROC: 0.5106034183530515\n",
      "AUPRC: 0.10098740969360868\n",
      "Accuracy: 0.11697341513292434\n",
      "AUROC: 0.5297708412616764\n",
      "AUPRC: 0.10737775739888533\n",
      "Accuracy: 0.28445807770961146\n",
      "AUROC: 0.5061651725370094\n",
      "AUPRC: 0.10005280424928553\n",
      "Accuracy: 0.13680981595092023\n",
      "AUROC: 0.5021502363517494\n",
      "AUPRC: 0.0984297586246487\n",
      "Accuracy: 0.15807770961145196\n"
     ]
    }
   ],
   "source": [
    "######### testing classifiers on scrambled samples as a negative control\n",
    "\n",
    "dataset_main = \"FateMap\"\n",
    "\n",
    "classifiers_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/classifiers\", dataset_main)\n",
    "print(classifiers_dir)\n",
    "\n",
    "# loading and formatting sample 2 data\n",
    "dataset_classifier = \"sample2\"\n",
    "dataset_predict = \"sample1\"\n",
    "\n",
    "counts_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment\", dataset_main, \"10X\", dataset_predict)\n",
    "labels_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment\", dataset_main, \"10X\", dataset_predict)\n",
    "results_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/predictions/\"\n",
    "summaries_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/datasetSummaries/\"\n",
    "features, labels_encoded, barcodes_1, matrix_array, genes = load_and_preprocess_data(counts_dir, labels_dir)\n",
    "\n",
    "#scerambling matrix\n",
    "flattened_matrix = matrix_array.flatten()\n",
    "np.random.shuffle(flattened_matrix)\n",
    "scrambled_matrix_array = flattened_matrix.reshape(matrix_array.shape)\n",
    "features_scrambled = scrambled_matrix_array\n",
    "\n",
    "summary_scrambled = pd.DataFrame(columns = [\"dataset\", \"condition\", \"auroc\", \"auprc\", \"accuracy\", \"best_params\"])\n",
    "\n",
    "#classifier list for Goyal et al. samples came from identifiying which classifiers points were randomly chosen to be plotted in classifierCrossExperimentPlots.R\n",
    "FMClassifierList_sample1 = [\"28\", \"27\", \"71\", \"42\", \"44\", \"33\", \"47\", \"16\", \"20\", \"92\"]\n",
    "FMClassifierList_sample2 = [\"39\", \"35\", \"69\", \"97\", \"30\", \"85\", \"76\", \"41\", \"9\", \"88\"]\n",
    "\n",
    "for count in FMClassifierList_sample2 :\n",
    "    sample1Classifier = load(classifiers_dir + f'/{dataset_classifier}_{count}_fit.joblib')\n",
    "    # predict sample 2 outcome using sample 1's classifier\n",
    "    preds_proba = sample1Classifier.predict_proba(features_scrambled)[:,1]  # Get probabilities of the positive class (multiplets- 1)\n",
    "    auroc = roc_auc_score(labels_encoded, preds_proba) # Calculate AUROC\n",
    "    print(f\"AUROC: {auroc}\")\n",
    "    auprc = average_precision_score(labels_encoded, preds_proba) # Calculate AUPRC\n",
    "    print(f\"AUPRC: {auprc}\")\n",
    "    y_preds = sample1Classifier.predict(features_scrambled) # Predict labels on the test set\n",
    "    accuracy = accuracy_score(labels_encoded, y_preds) # Calculate accuracy\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    summary_dict = {\"dataset\": dataset_predict, \"condition\": dataset_classifier, \"auroc\": auroc, \"auprc\": auprc, \"accuracy\": accuracy}  \n",
    "    summary_scrambled = pd.concat([summary_scrambled, pd.DataFrame([summary_dict])], ignore_index=True)\n",
    "\n",
    "summary_scrambled.to_csv(os.path.join(summaries_dir, dataset_main, f\"{dataset_predict}Scrambled_{dataset_classifier}Classifier.csv\"), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/classifiers/TREX_minusCluster\n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 261, 'singlet': 1896}\n",
      "AUROC: 0.9510766768514478\n",
      "AUPRC: 0.7707232602093118\n",
      "Accuracy: 0.9318497913769124\n",
      "AUROC: 0.9185662091598364\n",
      "AUPRC: 0.6838144774997007\n",
      "Accuracy: 0.9225776541492814\n",
      "AUROC: 0.9545120196582441\n",
      "AUPRC: 0.8114914466093169\n",
      "Accuracy: 0.943439962911451\n",
      "AUROC: 0.8617395767657661\n",
      "AUPRC: 0.5252227961227719\n",
      "Accuracy: 0.8525730180806675\n",
      "AUROC: 0.9137668331797534\n",
      "AUPRC: 0.724575773592798\n",
      "Accuracy: 0.8451553082985628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_49190/184098084.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([summary_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9290925036778375\n",
      "AUPRC: 0.7522399018261122\n",
      "Accuracy: 0.9188687992582291\n",
      "AUROC: 0.9535824563105227\n",
      "AUPRC: 0.8142084184347304\n",
      "Accuracy: 0.9397311080203987\n",
      "AUROC: 0.8995788673876846\n",
      "AUPRC: 0.6184635104884548\n",
      "Accuracy: 0.9114510894761243\n",
      "AUROC: 0.9421670142425271\n",
      "AUPRC: 0.7482209475989734\n",
      "Accuracy: 0.9049605934167826\n",
      "AUROC: 0.9176972695087056\n",
      "AUPRC: 0.6721937329922801\n",
      "Accuracy: 0.8915159944367177\n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 285, 'singlet': 2591}\n",
      "AUROC: 0.7310271046199056\n",
      "AUPRC: 0.2776028345167208\n",
      "Accuracy: 0.7576495132127955\n",
      "AUROC: 0.6885331816612159\n",
      "AUPRC: 0.19388688748460592\n",
      "Accuracy: 0.7593880389429764\n",
      "AUROC: 0.7325627848084124\n",
      "AUPRC: 0.252638909611973\n",
      "Accuracy: 0.7340055632823366\n",
      "AUROC: 0.6836227968609289\n",
      "AUPRC: 0.2012268288029272\n",
      "Accuracy: 0.7868567454798331\n",
      "AUROC: 0.7638749517560787\n",
      "AUPRC: 0.2674988583599915\n",
      "Accuracy: 0.8306675938803895\n",
      "AUROC: 0.7679199929580802\n",
      "AUPRC: 0.2724065236103098\n",
      "Accuracy: 0.8209318497913769\n",
      "AUROC: 0.7317570266848131\n",
      "AUPRC: 0.20806772390012673\n",
      "Accuracy: 0.7805980528511822\n",
      "AUROC: 0.7190341736239478\n",
      "AUPRC: 0.2164321387243605\n",
      "Accuracy: 0.6995827538247567\n",
      "AUROC: 0.7138624252642413\n",
      "AUPRC: 0.22063994376336046\n",
      "Accuracy: 0.7444367176634215\n",
      "AUROC: 0.758080264342833\n",
      "AUPRC: 0.23818273857337532\n",
      "Accuracy: 0.805980528511822\n"
     ]
    }
   ],
   "source": [
    "### classifier fit to sample 1 data to predict sample 2 outcome\n",
    "dataset_main = \"TREX_minusCluster\"\n",
    "\n",
    "classifiers_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/classifiers\", dataset_main)\n",
    "print(classifiers_dir)\n",
    "\n",
    "# loading and formatting sample 2 data\n",
    "\n",
    "dataset = \"sample2\"\n",
    "counts_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment\", dataset_main, \"10X\", dataset)\n",
    "labels_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment\", dataset_main, \"10X\", dataset)\n",
    "results_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/predictions/\"\n",
    "summaries_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/datasetSummaries/\"\n",
    "features, labels_encoded, barcodes_1, matrix_array, genes = load_and_preprocess_data(counts_dir, labels_dir)\n",
    "\n",
    "summary_df = pd.DataFrame(columns = [\"dataset\", \"condition\", \"auroc\", \"auprc\", \"accuracy\", \"best_params\"])\n",
    "\n",
    "for count in range(10):\n",
    "    sample1Classifier = load(classifiers_dir + f'/sample1_{count}_fit.joblib') #using the classifier that was fit to sample 1\n",
    "    # predict sample 2 outcome using sample 1's classifier\n",
    "    preds_proba = sample1Classifier.predict_proba(features)[:,1]  # Get probabilities of the positive class (multiplets- 1)\n",
    "    auroc = roc_auc_score(labels_encoded, preds_proba) # Calculate AUROC\n",
    "    print(f\"AUROC: {auroc}\")\n",
    "    auprc = average_precision_score(labels_encoded, preds_proba) # Calculate AUPRC\n",
    "    print(f\"AUPRC: {auprc}\")\n",
    "    y_preds = sample1Classifier.predict(features) # Predict labels on the test set\n",
    "    accuracy = accuracy_score(labels_encoded, y_preds) # Calculate accuracy\n",
    "    print(f\"Accuracy: {accuracy}\")  \n",
    "    summary_dict = {\"dataset\": dataset, \"condition\": \"sample1\", \"auroc\": auroc, \"auprc\": auprc, \"accuracy\": accuracy}  \n",
    "    summary_df = pd.concat([summary_df, pd.DataFrame([summary_dict])], ignore_index=True)\n",
    "\n",
    "#loading and formatting sample 2 data\n",
    "\n",
    "dataset = \"sample1\"\n",
    "counts_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment\", dataset_main, \"10X\", dataset)\n",
    "labels_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment\", dataset_main, \"10X\", dataset)\n",
    "results_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/predictions/\"\n",
    "summaries_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/datasetSummaries/\"\n",
    "features, labels_encoded, barcodes_1, matrix_array, genes = load_and_preprocess_data(counts_dir, labels_dir)\n",
    "\n",
    "for count in range(10):\n",
    "    sample1Classifier = load(classifiers_dir + f'/sample2_{count}_fit.joblib') #using the classifier that was fit to sample 1\n",
    "    # predict sample 2 outcome using sample 1's classifier\n",
    "    preds_proba = sample1Classifier.predict_proba(features)[:,1]  # Get probabilities of the positive class (multiplets- 1)\n",
    "    auroc = roc_auc_score(labels_encoded, preds_proba) # Calculate AUROC\n",
    "    print(f\"AUROC: {auroc}\")\n",
    "    auprc = average_precision_score(labels_encoded, preds_proba) # Calculate AUPRC\n",
    "    print(f\"AUPRC: {auprc}\")\n",
    "    y_preds = sample1Classifier.predict(features) # Predict labels on the test set\n",
    "    accuracy = accuracy_score(labels_encoded, y_preds) # Calculate accuracy\n",
    "    print(f\"Accuracy: {accuracy}\")  \n",
    "    summary_dict = {\"dataset\": dataset, \"condition\": \"sample2\", \"auroc\": auroc, \"auprc\": auprc, \"accuracy\": accuracy}  \n",
    "    summary_df = pd.concat([summary_df, pd.DataFrame([summary_dict])], ignore_index=True)\n",
    "\n",
    "# loading and formatting sample 3 data\n",
    "\n",
    "# dataset = \"TREX1_A_mouse\"\n",
    "# counts_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment\", dataset_main, \"10X\", dataset)\n",
    "# labels_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment\", dataset_main, \"10X\", dataset)\n",
    "# results_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/predictions/\"\n",
    "# summaries_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/datasetSummaries/\"\n",
    "# features, labels_encoded, barcodes_1, matrix_array, genes = load_and_preprocess_data(counts_dir, labels_dir)\n",
    "\n",
    "# for count in range(10):\n",
    "#     sample2Classifier = load(classifiers_dir + f'/B_mouse_{count}_fit.joblib')\n",
    "#     # predict sample 1 outcome using sample 2's classifier\n",
    "#     preds_proba = sample2Classifier.predict_proba(features)[:,1]  # Get probabilities of the positive class (multiplets- 1)\n",
    "#     auroc = roc_auc_score(labels_encoded, preds_proba) # Calculate AUROC\n",
    "#     print(f\"AUROC: {auroc}\")\n",
    "#     auprc = average_precision_score(labels_encoded, preds_proba) # Calculate AUPRC\n",
    "#     print(f\"AUPRC: {auprc}\")\n",
    "#     y_preds = sample2Classifier.predict(features) # Predict labels on the test set\n",
    "#     accuracy = accuracy_score(labels_encoded, y_preds) # Calculate accuracy\n",
    "#     print(f\"Accuracy: {accuracy}\")  \n",
    "#     summary_dict = {\"dataset\": dataset, \"condition\": \"B_mouse\", \"auroc\": auroc, \"auprc\": auprc, \"accuracy\": accuracy}  \n",
    "#     summary_df = pd.concat([summary_df, pd.DataFrame([summary_dict])], ignore_index=True)\n",
    "    \n",
    "summary_df.to_csv(os.path.join(summaries_dir, dataset_main, f\"summary_s1s2_bothClassifiers.csv\"), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 135, 'singlet': 1215}\n",
      "AUROC: 0.8515165371132449\n",
      "AUPRC: 0.5098618964226356\n",
      "Accuracy: 0.9096296296296297\n",
      "AUROC: 0.8658802011888432\n",
      "AUPRC: 0.5072343603720617\n",
      "Accuracy: 0.9044444444444445\n",
      "AUROC: 0.8347508001828989\n",
      "AUPRC: 0.34345829549838924\n",
      "Accuracy: 0.9014814814814814\n",
      "AUROC: 0.8767931717725956\n",
      "AUPRC: 0.5058655729883778\n",
      "Accuracy: 0.9007407407407407\n",
      "AUROC: 0.8410973936899863\n",
      "AUPRC: 0.4090397503696277\n",
      "Accuracy: 0.9007407407407407\n",
      "AUROC: 0.7955067825026673\n",
      "AUPRC: 0.36807780587320094\n",
      "Accuracy: 0.9051851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_48165/512674007.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame([summary_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.8939003200731596\n",
      "AUPRC: 0.5099632387185461\n",
      "Accuracy: 0.9081481481481481\n",
      "AUROC: 0.8743789056546258\n",
      "AUPRC: 0.5357379806832681\n",
      "Accuracy: 0.902962962962963\n",
      "AUROC: 0.8952903520804756\n",
      "AUPRC: 0.538431626399674\n",
      "Accuracy: 0.9044444444444445\n",
      "AUROC: 0.8758847736625516\n",
      "AUPRC: 0.47777191050308376\n",
      "Accuracy: 0.9022222222222223\n",
      "Index([], dtype='object')\n",
      "Index(['barcode', 'label', 'sample'], dtype='object')\n",
      "{'doublet': 96, 'singlet': 864}\n",
      "AUROC: 0.8838252314814815\n",
      "AUPRC: 0.5555276873563401\n",
      "Accuracy: 0.9104166666666667\n",
      "AUROC: 0.854275173611111\n",
      "AUPRC: 0.48182607364034485\n",
      "Accuracy: 0.8645833333333334\n",
      "AUROC: 0.8705994405864197\n",
      "AUPRC: 0.5382235540883269\n",
      "Accuracy: 0.890625\n",
      "AUROC: 0.8704306520061728\n",
      "AUPRC: 0.48657110356699407\n",
      "Accuracy: 0.8104166666666667\n",
      "AUROC: 0.8851996527777779\n",
      "AUPRC: 0.5629344182617926\n",
      "Accuracy: 0.8677083333333333\n",
      "AUROC: 0.8966169945987654\n",
      "AUPRC: 0.5243092648565193\n",
      "Accuracy: 0.85625\n",
      "AUROC: 0.8794126157407408\n",
      "AUPRC: 0.6042074574858988\n",
      "Accuracy: 0.80625\n",
      "AUROC: 0.9078534915123456\n",
      "AUPRC: 0.5797851739246085\n",
      "Accuracy: 0.8885416666666667\n",
      "AUROC: 0.8692491319444445\n",
      "AUPRC: 0.5313703535371472\n",
      "Accuracy: 0.8760416666666667\n",
      "AUROC: 0.8412905092592592\n",
      "AUPRC: 0.40522204113887267\n",
      "Accuracy: 0.83125\n"
     ]
    }
   ],
   "source": [
    "# loading and formatting sample 3 data for sample 1 classifier (can only do when 1-4 are integrated together)\n",
    "\n",
    "dataset_main = \"SPLINTR\"\n",
    "classifiers_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/classifiers\", dataset_main)\n",
    "\n",
    "dataset = \"sample3_s1s2s3s4\"\n",
    "counts_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment\", dataset_main, \"10X\", dataset)\n",
    "labels_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment\", dataset_main, \"10X\", dataset)\n",
    "results_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/predictions/\"\n",
    "summaries_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/datasetSummaries/\"\n",
    "features, labels_encoded, barcodes_1, matrix_array, genes = load_and_preprocess_data(counts_dir, labels_dir)\n",
    "\n",
    "summary_df = pd.DataFrame(columns = [\"dataset\", \"condition\", \"auroc\", \"auprc\", \"accuracy\", \"best_params\"])\n",
    "\n",
    "for count in range(10):\n",
    "    sample1Classifier = load(classifiers_dir + f'/sample1_s1s2s3s4_{count}_fit.joblib') #using the classifier that was fit to sample 1\n",
    "    # predict sample 2 outcome using sample 1's classifier\n",
    "    preds_proba = sample1Classifier.predict_proba(features)[:,1]  # Get probabilities of the positive class (multiplets- 1)\n",
    "    auroc = roc_auc_score(labels_encoded, preds_proba) # Calculate AUROC\n",
    "    print(f\"AUROC: {auroc}\")\n",
    "    auprc = average_precision_score(labels_encoded, preds_proba) # Calculate AUPRC\n",
    "    print(f\"AUPRC: {auprc}\")\n",
    "    y_preds = sample1Classifier.predict(features) # Predict labels on the test set\n",
    "    accuracy = accuracy_score(labels_encoded, y_preds) # Calculate accuracy\n",
    "    print(f\"Accuracy: {accuracy}\")  \n",
    "    summary_dict = {\"dataset\": dataset, \"condition\": \"sample1_s1s2s3s4\", \"auroc\": auroc, \"auprc\": auprc, \"accuracy\": accuracy}  \n",
    "    summary_df = pd.concat([summary_df, pd.DataFrame([summary_dict])], ignore_index=True)\n",
    "\n",
    "# loading and formatting sample 1 data for sample 3 classifier\n",
    "\n",
    "dataset = \"sample1_s1s2s3s4\"\n",
    "counts_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment\", dataset_main, \"10X\", dataset)\n",
    "labels_dir = os.path.join(\"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment\", dataset_main, \"10X\", dataset)\n",
    "results_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/predictions/\"\n",
    "summaries_dir = \"/Volumes/fsmresfiles/Basic_Sciences/CDB/GoyalLab/People/MadelineMelzer/ZhangMelzerEtAl/data/classifier/crossExperiment/results/datasetSummaries/\"\n",
    "features, labels_encoded, barcodes_1, matrix_array, genes = load_and_preprocess_data(counts_dir, labels_dir)\n",
    "\n",
    "for count in range(10):\n",
    "    sample3Classifier = load(classifiers_dir + f'/sample3_s1s2s3s4_{count}_fit.joblib')\n",
    "    # predict sample 1 outcome using sample 2's classifier\n",
    "    preds_proba = sample3Classifier.predict_proba(features)[:,1]  # Get probabilities of the positive class (multiplets- 1)\n",
    "    auroc = roc_auc_score(labels_encoded, preds_proba) # Calculate AUROC\n",
    "    print(f\"AUROC: {auroc}\")\n",
    "    auprc = average_precision_score(labels_encoded, preds_proba) # Calculate AUPRC\n",
    "    print(f\"AUPRC: {auprc}\")\n",
    "    y_preds = sample3Classifier.predict(features) # Predict labels on the test set\n",
    "    accuracy = accuracy_score(labels_encoded, y_preds) # Calculate accuracy\n",
    "    print(f\"Accuracy: {accuracy}\")  \n",
    "    summary_dict = {\"dataset\": dataset, \"condition\": \"sample3_s1s2s3s4\", \"auroc\": auroc, \"auprc\": auprc, \"accuracy\": accuracy}  \n",
    "    summary_df = pd.concat([summary_df, pd.DataFrame([summary_dict])], ignore_index=True)\n",
    "    \n",
    "summary_df.to_csv(os.path.join(summaries_dir, dataset_main, f\"summary_s1s3_bothClassifiers.csv\"), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
