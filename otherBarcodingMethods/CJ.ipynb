{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T16:36:26.081739Z",
     "start_time": "2023-10-10T16:36:26.077510Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adopting smartseq3 data (MoldEtAl, \"Clonally heritable gene expression imparts a layer of diversity within cell types\",bioRxiv 2022) data for ZhangMelzerEtAl 2023\n",
    "#Last updated 20231205 by Madeline E Melzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T00:45:26.893503Z",
     "start_time": "2023-11-03T00:45:26.617764Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import csv\n",
    "\n",
    "#import gzip\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#import scipy.io\n",
    "#import pyreadr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T00:51:15.341074Z",
     "start_time": "2023-11-03T00:51:15.314408Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expand_rows_based_on_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/scripts/singletCode/otherBarcodingMethods/CJ.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe%20and%20Goyal%20Labs/ZhangMelzerEtAl/scripts/singletCode/otherBarcodingMethods/CJ.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m outputDirectory2 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/CJ/read_count_matrices/formatted/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe%20and%20Goyal%20Labs/ZhangMelzerEtAl/scripts/singletCode/otherBarcodingMethods/CJ.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#format_umi_count_matrices(inputDirectory, outputDirectory)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe%20and%20Goyal%20Labs/ZhangMelzerEtAl/scripts/singletCode/otherBarcodingMethods/CJ.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m expand_rows_based_on_count(outputDirectory, outputDirectory)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe%20and%20Goyal%20Labs/ZhangMelzerEtAl/scripts/singletCode/otherBarcodingMethods/CJ.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#append_csv_files(outputDirectory, os.path.join(outputDirectory2, \"all_brains_read_count_matrix.csv\"))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expand_rows_based_on_count' is not defined"
     ]
    }
   ],
   "source": [
    "inputDirectory = \"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/CJ/umi_count/\"\n",
    "outputDirectory = inputDirectory\n",
    "outputDirectory2 = \"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/CJ/read_count_matrices/formatted/\"\n",
    "\n",
    "#format_umi_count_matrices(inputDirectory, outputDirectory)\n",
    "expand_rows_based_on_count(outputDirectory, outputDirectory)\n",
    "\n",
    "#append_csv_files(outputDirectory, os.path.join(outputDirectory2, \"all_brains_read_count_matrix.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering barcodes with \"0\" (deleted bases) or \"-\" (missing bases)\n",
    "\n",
    "dataframe = pd.read_csv(os.path.join(outputDirectory2, \"all_brains_read_count_matrix.csv\"))\n",
    "filtered_df = dataframe[~dataframe['barcode'].str.contains('0') & ~dataframe['barcode'].str.contains('-')]\n",
    "filtered_df.to_csv(os.path.join(outputDirectory2, \"all_brains_read_count_matrix_filtered.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T00:41:41.009955Z",
     "start_time": "2023-10-14T00:41:40.765704Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cellID</th>\n",
       "      <th>barcode</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10x52_AAACCCAGTAGCCAGA</td>\n",
       "      <td>GTGTGCAGCTTTGAAGGGTGATGTGGGGGG</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10x52_AAACCCAGTAGCCAGA</td>\n",
       "      <td>GTGTGCAGCTTTGAAGGGTGATGTGGGGGG</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10x52_AAACCCAGTAGCCAGA</td>\n",
       "      <td>TTGGCGGAGCGGGGGGAGGGAGGGCGATAC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10x52_AAACGCTAGCATGATA</td>\n",
       "      <td>TATTGTGCCGCCCGAGAGTAGCGTGGGGGC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10x52_AAACGCTAGCATGATA</td>\n",
       "      <td>TATTGTGCCGCCCGAGAGTAGCGTGGGGGC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cellID                         barcode sample\n",
       "0  10x52_AAACCCAGTAGCCAGA  GTGTGCAGCTTTGAAGGGTGATGTGGGGGG      3\n",
       "1  10x52_AAACCCAGTAGCCAGA  GTGTGCAGCTTTGAAGGGTGATGTGGGGGG      3\n",
       "2  10x52_AAACCCAGTAGCCAGA  TTGGCGGAGCGGGGGGAGGGAGGGCGATAC      3\n",
       "3  10x52_AAACGCTAGCATGATA  TATTGTGCCGCCCGAGAGTAGCGTGGGGGC      3\n",
       "4  10x52_AAACGCTAGCATGATA  TATTGTGCCGCCCGAGAGTAGCGTGGGGGC      3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining all brains into one file\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for filename in os.listdir(outputDirectory2):\n",
    "    if filename.startswith(\"brain\") and filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(outputDirectory2, filename)\n",
    "\n",
    "        # Extract sample number from filename\n",
    "        sample_number = filename.split(\"_\")[0].replace(\"brain\", \"\")\n",
    "\n",
    "        # Read the .csv file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Add the sample column\n",
    "        df['sample'] = sample_number\n",
    "\n",
    "        # Append to the list of DataFrames\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames together\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new .csv file\n",
    "combined_output_path_script = os.path.join(outputDirectory2, \"all_brains_umi_count_matrix.csv\")\n",
    "combined_df.to_csv(combined_output_path_script, index=False)\n",
    "\n",
    "# Display the first few rows of the combined data for verification\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T00:45:30.707Z",
     "start_time": "2023-11-03T00:45:30.700918Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_umi_count_matrices(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Transform UMI count matrices from all CSV files in a given folder and save the transformed data to new CSV files in the output folder.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder: Path to the input folder containing CSV files.\n",
    "    - output_folder: Path where the transformed CSV files will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate over each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            # Construct full paths for input and output files\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename.replace(\".csv\", \"_formatted.csv\"))\n",
    "\n",
    "            # Load the CSV file into a DataFrame\n",
    "            df = pd.read_csv(input_path, index_col=0)\n",
    "\n",
    "            # Melt the DataFrame to reshape it\n",
    "            melted_df = df.reset_index().melt(id_vars='index', var_name='cellID', value_name='count')\n",
    "\n",
    "            # Rename columns and reorder them\n",
    "            melted_df = melted_df.rename(columns={'index': 'barcode'})\n",
    "            melted_df = melted_df[['cellID', 'barcode', 'count']]\n",
    "\n",
    "            # Remove rows where count is 0\n",
    "            filtered_df = melted_df[melted_df['count'] != 0].reset_index(drop=True)\n",
    "\n",
    "            # Save the filtered data to the specified output path\n",
    "            filtered_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T00:00:04.813083Z",
     "start_time": "2023-10-14T00:00:04.808321Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def append_csv_files(input_folder, output_path):\n",
    "    \"\"\"\n",
    "    Append all .csv files in a given folder into one .csv file.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder: Path to the input folder containing the .csv files.\n",
    "    - output_path: Path where the combined .csv file will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # List to hold individual DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\"_formatted.csv\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Read the .csv file into a DataFrame and append to the list\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Extract the sample name from the filename\n",
    "            sample_name = filename.split('_')[3]\n",
    "            df['sample'] = sample_name\n",
    "            dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames together\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to the specified output path\n",
    "    combined_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T00:51:10.090716Z",
     "start_time": "2023-11-03T00:51:10.090400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def expand_rows_based_on_count(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    For each .csv file in the input folder ending with \"_formatted.csv\", duplicate rows based on the \"count\" value\n",
    "    and then drop the \"count\" column. The processed data is saved to the specified output folder with the same filename.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder: Path to the folder containing the .csv files.\n",
    "    - output_folder: Path to the folder where the processed files will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate over each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\"_formatted.csv\"):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Read the .csv file into a DataFrame\n",
    "            df = pd.read_csv(input_path)\n",
    "\n",
    "            # Duplicate rows based on the \"count\" column\n",
    "            df = df.loc[df.index.repeat(df['count'])]\n",
    "\n",
    "            # Drop the \"count\" column\n",
    "            df = df.drop(columns=['count']).reset_index(drop=True)\n",
    "\n",
    "            # Save the processed DataFrame to the specified output path\n",
    "            df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping cellID for the UMI count file using the cellID in the read count file\n",
    "\n",
    "read_count_matrix = pd.read_csv(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/CJ/read_count_matrices/formatted/all_brains_read_count_matrix_filtered.csv\")\n",
    "umi_count_matrix = pd.read_csv(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/CJ/umi_count/lineageBC_results_UMIonly_formatted.csv\")\n",
    "\n",
    "# Create a mapping from cellID to sample\n",
    "cellID_to_sample_mapping = read_count_matrix[['cellID', 'sample']].drop_duplicates()\n",
    "\n",
    "# Merge the mapping with the lineageBC_df dataframe\n",
    "merged_df = umi_count_matrix.merge(cellID_to_sample_mapping, on='cellID', how='left')\n",
    "merged_df.head()\n",
    "\n",
    "# Filter merged_df to exclude rows where 'sample' is missing\n",
    "merged_df = merged_df[merged_df['sample'].notnull()]\n",
    "\n",
    "\n",
    "merged_df.to_csv(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/CJ/umi_count/lineageBC_results_UMIonly_formatted_mapped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 158 cellIDs in umi_count_matrix that are not present in merged_df.\n",
      "There are 0 unique cellIDs without a sample.\n"
     ]
    }
   ],
   "source": [
    "# checking that all cellIDs from umi_count_matrix are present in merged_df\n",
    "\n",
    "# Get unique cellIDs in umi_count_matrix and merged_df\n",
    "umi_cellIDs = set(umi_count_matrix['cellID'].unique())\n",
    "merged_cellIDs = set(merged_df['cellID'].unique())\n",
    "\n",
    "# Check if all cellIDs in umi_count_matrix are present in merged_df\n",
    "if umi_cellIDs.issubset(merged_cellIDs):\n",
    "    print(\"All cellIDs in umi_count_matrix are present in merged_df.\")\n",
    "else:\n",
    "    missing_cellIDs = umi_cellIDs - merged_cellIDs\n",
    "    print(f\"There are {len(missing_cellIDs)} cellIDs in umi_count_matrix that are not present in merged_df.\")\n",
    "\n",
    "\n",
    "# Create a subset of merged_df where 'sample' is missing\n",
    "missing_samples_df = merged_df[merged_df['sample'].isnull()]\n",
    "\n",
    "# Count the number of unique cellIDs in this subset\n",
    "num_unique_missing_samples = missing_samples_df['cellID'].nunique()\n",
    "\n",
    "\n",
    "print(f\"There are {num_unique_missing_samples} unique cellIDs without a sample.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain1_only = merged_df[merged_df['sample'] == 'brain1']\n",
    "brain2_only = merged_df[merged_df['sample'] == 'brain2']\n",
    "\n",
    "brain1_only.to_csv(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/CJ/umi_count/brain1_only.csv\", index=False)\n",
    "brain2_only.to_csv(\"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/CJ/umi_count/brain2_only.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
