{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-10T16:36:26.081739Z",
     "start_time": "2023-10-10T16:36:26.077510Z"
    }
   },
   "outputs": [],
   "source": [
    "#Adopting TREX (RatzEtAl Nat Neuro 2022) data for ZhangMelzerEtAl 2023\n",
    "#Last updated 20231003 by Madeline E Melzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#import csv\n",
    "#import gzip\n",
    "import os\n",
    "import pandas as pd\n",
    "#import scipy.io\n",
    "#import pyreadr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T00:45:26.893503Z",
     "start_time": "2023-11-03T00:45:26.617764Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "inputDirectory = \"/Users/mem3579/Documents/GitHub/TREX/trex_singletCode/\"\n",
    "outputDirectory = \"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/CJ/\"\n",
    "outputDirectory2 = \"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/CJ/formatted/\"\n",
    "#outputDirectory2 = \"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/ZhangMelzerEtAl/data/TREX/cloneID/formatted2/\"\n",
    "\n",
    "#format_umi_count_matrices(outputDirectory, outputDirectory2)\n",
    "\n",
    "#append_csv_files(outputDirectory, os.path.join(outputDirectory, \"all_brains_umi_count_matrix.csv\"))\n",
    "\n",
    "expand_rows_based_on_count(outputDirectory, outputDirectory2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T00:51:15.341074Z",
     "start_time": "2023-11-03T00:51:15.314408Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "                   cellID                         barcode sample\n0  10x52_AAACCCAGTAGCCAGA  GTGTGCAGCTTTGAAGGGTGATGTGGGGGG      3\n1  10x52_AAACCCAGTAGCCAGA  GTGTGCAGCTTTGAAGGGTGATGTGGGGGG      3\n2  10x52_AAACCCAGTAGCCAGA  TTGGCGGAGCGGGGGGAGGGAGGGCGATAC      3\n3  10x52_AAACGCTAGCATGATA  TATTGTGCCGCCCGAGAGTAGCGTGGGGGC      3\n4  10x52_AAACGCTAGCATGATA  TATTGTGCCGCCCGAGAGTAGCGTGGGGGC      3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cellID</th>\n      <th>barcode</th>\n      <th>sample</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10x52_AAACCCAGTAGCCAGA</td>\n      <td>GTGTGCAGCTTTGAAGGGTGATGTGGGGGG</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10x52_AAACCCAGTAGCCAGA</td>\n      <td>GTGTGCAGCTTTGAAGGGTGATGTGGGGGG</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10x52_AAACCCAGTAGCCAGA</td>\n      <td>TTGGCGGAGCGGGGGGAGGGAGGGCGATAC</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10x52_AAACGCTAGCATGATA</td>\n      <td>TATTGTGCCGCCCGAGAGTAGCGTGGGGGC</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10x52_AAACGCTAGCATGATA</td>\n      <td>TATTGTGCCGCCCGAGAGTAGCGTGGGGGC</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for filename in os.listdir(outputDirectory2):\n",
    "    if filename.startswith(\"brain\") and filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(outputDirectory2, filename)\n",
    "\n",
    "        # Extract sample number from filename\n",
    "        sample_number = filename.split(\"_\")[0].replace(\"brain\", \"\")\n",
    "\n",
    "        # Read the .csv file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Add the sample column\n",
    "        df['sample'] = sample_number\n",
    "\n",
    "        # Append to the list of DataFrames\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames together\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new .csv file\n",
    "combined_output_path_script = os.path.join(outputDirectory2, \"all_brains_umi_count_matrix.csv\")\n",
    "combined_df.to_csv(combined_output_path_script, index=False)\n",
    "\n",
    "# Display the first few rows of the combined data for verification\n",
    "combined_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T00:41:41.009955Z",
     "start_time": "2023-10-14T00:41:40.765704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def format_umi_count_matrices(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Transform UMI count matrices from all CSV files in a given folder and save the transformed data to new CSV files in the output folder.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder: Path to the input folder containing CSV files.\n",
    "    - output_folder: Path where the transformed CSV files will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate over each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            # Construct full paths for input and output files\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename.replace(\".csv\", \"_formatted.csv\"))\n",
    "\n",
    "            # Load the CSV file into a DataFrame\n",
    "            df = pd.read_csv(input_path, index_col=0)\n",
    "\n",
    "            # Melt the DataFrame to reshape it\n",
    "            melted_df = df.reset_index().melt(id_vars='index', var_name='cellID', value_name='count')\n",
    "\n",
    "            # Rename columns and reorder them\n",
    "            melted_df = melted_df.rename(columns={'index': 'barcode'})\n",
    "            melted_df = melted_df[['cellID', 'barcode', 'count']]\n",
    "\n",
    "            # Remove rows where count is 0\n",
    "            filtered_df = melted_df[melted_df['count'] != 0].reset_index(drop=True)\n",
    "\n",
    "            # Save the filtered data to the specified output path\n",
    "            filtered_df.to_csv(output_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T00:45:30.707Z",
     "start_time": "2023-11-03T00:45:30.700918Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def append_csv_files(input_folder, output_path):\n",
    "    \"\"\"\n",
    "    Append all .csv files in a given folder into one .csv file.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder: Path to the input folder containing the .csv files.\n",
    "    - output_path: Path where the combined .csv file will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # List to hold individual DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Read the .csv file into a DataFrame and append to the list\n",
    "            df = pd.read_csv(file_path)\n",
    "            dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames together\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to the specified output path\n",
    "    combined_df.to_csv(output_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T00:00:04.813083Z",
     "start_time": "2023-10-14T00:00:04.808321Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def expand_rows_based_on_count(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    For each .csv file in the input folder ending with \"_formatted.csv\", duplicate rows based on the \"count\" value\n",
    "    and then drop the \"count\" column. The processed data is saved to the specified output folder with the same filename.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder: Path to the folder containing the .csv files.\n",
    "    - output_folder: Path to the folder where the processed files will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate over each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\"_formatted.csv\"):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Read the .csv file into a DataFrame\n",
    "            df = pd.read_csv(input_path)\n",
    "\n",
    "            # Duplicate rows based on the \"count\" column\n",
    "            df = df.loc[df.index.repeat(df['count'])]\n",
    "\n",
    "            # Drop the \"count\" column\n",
    "            df = df.drop(columns=['count']).reset_index(drop=True)\n",
    "\n",
    "            # Save the processed DataFrame to the specified output path\n",
    "            df.to_csv(output_path, index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T00:51:10.090716Z",
     "start_time": "2023-11-03T00:51:10.090400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
